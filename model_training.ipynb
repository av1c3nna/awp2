{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "\n",
    "from Preprocessing import *\n",
    "\n",
    "prep = Preprocessing()\n",
    "\n",
    "merged_hornsea = prep.perform_preprocessing_pipeline(geo_data_dict = {\"dwd_icon_eu_hornsea\":\"nc_files\", \"ncep_gfs_hornsea\":\"nc_files\"},\n",
    "          deployment = False, energy_data_dict = {\"Energy_data\":\"csv_files\"})\n",
    "\n",
    "merged_pes = prep.perform_preprocessing_pipeline(geo_data_dict = {\"dwd_icon_eu_pes\":\"nc_files\", \"ncep_gfs_pes\":\"nc_files\"},\n",
    "          deployment = False, energy_data_dict = {\"Energy_data\":\"csv_files\"})\n",
    "\n",
    "merged_demand = prep.perform_preprocessing_pipeline(geo_data_dict = {\"dwd_icon_eu_demand\":\"nc_files\", \"ncep_gfs_demand\":\"nc_files\"},\n",
    "          deployment = False, energy_data_dict = {\"Energy_data\":\"csv_files\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hornsea.to_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "merged_pes.to_parquet(\"preprocessed_pes_with_energy.parquet\")\n",
    "merged_demand.to_parquet(\"preprocessed_demand_with_energy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing import *\n",
    "merged_hornsea = pd.read_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "merged_pes = pd.read_parquet(\"preprocessed_pes_with_energy.parquet\")\n",
    "merged_demand = pd.read_parquet(\"preprocessed_demand_with_energy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "feature_engineerer_wind = FeatureEngineerer(merged_hornsea, label = 'Wind_MWh_credit')\n",
    "feature_engineerer_solar = FeatureEngineerer(merged_pes, label = 'Solar_MWh_credit')\n",
    "\n",
    "merged_pes_simple = merged_pes[['solar_down_rad', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_solar_baseline = FeatureEngineerer(merged_pes_simple, label = 'Solar_MWh_credit')\n",
    "\n",
    "merged_hornsea_simple = merged_hornsea[['wind_speed_100', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_wind_baseline = FeatureEngineerer(merged_hornsea_simple, label = 'Wind_MWh_credit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Wind Energy Forecast__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__baseline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Quantile Regressor model for quantile 0.1 to qr_model_wind\\qr_model_quantile_0.1.pkl\n",
      "Saved Quantile Regressor model for quantile 0.2 to qr_model_wind\\qr_model_quantile_0.2.pkl\n",
      "Saved Quantile Regressor model for quantile 0.30000000000000004 to qr_model_wind\\qr_model_quantile_0.30000000000000004.pkl\n",
      "Saved Quantile Regressor model for quantile 0.4 to qr_model_wind\\qr_model_quantile_0.4.pkl\n",
      "Saved Quantile Regressor model for quantile 0.5 to qr_model_wind\\qr_model_quantile_0.5.pkl\n",
      "Saved Quantile Regressor model for quantile 0.6 to qr_model_wind\\qr_model_quantile_0.6.pkl\n",
      "Saved Quantile Regressor model for quantile 0.7000000000000001 to qr_model_wind\\qr_model_quantile_0.7000000000000001.pkl\n",
      "Saved Quantile Regressor model for quantile 0.8 to qr_model_wind\\qr_model_quantile_0.8.pkl\n",
      "Saved Quantile Regressor model for quantile 0.9 to qr_model_wind\\qr_model_quantile_0.9.pkl\n",
      "Quantile Regressor Pinball Score: 53.08909151412246\n"
     ]
    }
   ],
   "source": [
    "import model_utils\n",
    "import importlib\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"qr_model_wind\"\n",
    "\n",
    "qr_model = model_utils.QuantileRegressorModel(feature_engineerer_wind_baseline, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "qr_model.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {qr_model.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xgboost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rel_hum', 'temp', 'wind_dir', 'wind_dir_100', 'wind_speed',\n",
       "       'wind_speed_100', 'forecast_horizon', 'temp_mean', 'temp_std',\n",
       "       'temp_min', 'temp_max', 'wind_speed_mean', 'wind_speed_std',\n",
       "       'wind_speed_min', 'wind_speed_max', 'wind_speed_100_mean',\n",
       "       'wind_speed_100_std', 'wind_speed_100_min', 'wind_speed_100_max',\n",
       "       'wind_speed_range', 'wind_speed_100_range', 'wind_speed_altitude_diff',\n",
       "       'temp_range', 'sin_month', 'cos_month', 'sin_day', 'cos_day',\n",
       "       'sin_dayofweek', 'cos_dayofweek', 'sin_hour', 'cos_hour',\n",
       "       'rel_hum_diff', 'temp_diff', 'wind_speed_diff', 'Wind_MWh_credit',\n",
       "       'Solar_MWh_credit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_hornsea.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-quantile:94.90643\tVal-quantile:87.66962\n",
      "[1]\tTrain-quantile:90.85881\tVal-quantile:84.59971\n",
      "[2]\tTrain-quantile:86.99507\tVal-quantile:81.67438\n",
      "[3]\tTrain-quantile:83.30926\tVal-quantile:78.90810\n",
      "[4]\tTrain-quantile:79.79981\tVal-quantile:76.30057\n",
      "[5]\tTrain-quantile:76.44105\tVal-quantile:73.83583\n",
      "[6]\tTrain-quantile:73.24606\tVal-quantile:71.48407\n",
      "[7]\tTrain-quantile:70.19986\tVal-quantile:69.23573\n",
      "[8]\tTrain-quantile:67.29435\tVal-quantile:67.09918\n",
      "[9]\tTrain-quantile:64.55494\tVal-quantile:65.06881\n",
      "[10]\tTrain-quantile:61.95088\tVal-quantile:63.15929\n",
      "[11]\tTrain-quantile:59.46669\tVal-quantile:61.37005\n",
      "[12]\tTrain-quantile:57.10618\tVal-quantile:59.66145\n",
      "[13]\tTrain-quantile:54.85920\tVal-quantile:58.04787\n",
      "[14]\tTrain-quantile:52.72404\tVal-quantile:56.53057\n",
      "[15]\tTrain-quantile:50.67193\tVal-quantile:55.07907\n",
      "[16]\tTrain-quantile:48.71840\tVal-quantile:53.72495\n",
      "[17]\tTrain-quantile:46.86247\tVal-quantile:52.42748\n",
      "[18]\tTrain-quantile:45.09735\tVal-quantile:51.18923\n",
      "[19]\tTrain-quantile:43.41956\tVal-quantile:50.02819\n",
      "[20]\tTrain-quantile:41.81401\tVal-quantile:48.93784\n",
      "[21]\tTrain-quantile:40.28638\tVal-quantile:47.92760\n",
      "[22]\tTrain-quantile:38.83225\tVal-quantile:46.97656\n",
      "[23]\tTrain-quantile:37.45033\tVal-quantile:46.06263\n",
      "[24]\tTrain-quantile:36.12956\tVal-quantile:45.17952\n",
      "[25]\tTrain-quantile:34.87646\tVal-quantile:44.33127\n",
      "[26]\tTrain-quantile:33.68206\tVal-quantile:43.52802\n",
      "[27]\tTrain-quantile:32.55395\tVal-quantile:42.76616\n",
      "[28]\tTrain-quantile:31.47525\tVal-quantile:42.06088\n",
      "[29]\tTrain-quantile:30.44962\tVal-quantile:41.37715\n",
      "[30]\tTrain-quantile:29.47601\tVal-quantile:40.75413\n",
      "[31]\tTrain-quantile:28.55072\tVal-quantile:40.16886\n",
      "[32]\tTrain-quantile:27.67141\tVal-quantile:39.62817\n",
      "[33]\tTrain-quantile:26.83846\tVal-quantile:39.10341\n",
      "[34]\tTrain-quantile:26.04260\tVal-quantile:38.60544\n",
      "[35]\tTrain-quantile:25.29301\tVal-quantile:38.14899\n",
      "[36]\tTrain-quantile:24.57514\tVal-quantile:37.71153\n",
      "[37]\tTrain-quantile:23.89765\tVal-quantile:37.30170\n",
      "[38]\tTrain-quantile:23.24877\tVal-quantile:36.90878\n",
      "[39]\tTrain-quantile:22.64492\tVal-quantile:36.54575\n",
      "[40]\tTrain-quantile:22.07524\tVal-quantile:36.21288\n",
      "[41]\tTrain-quantile:21.53915\tVal-quantile:35.87763\n",
      "[42]\tTrain-quantile:21.02979\tVal-quantile:35.57603\n",
      "[43]\tTrain-quantile:20.55690\tVal-quantile:35.28341\n",
      "[44]\tTrain-quantile:20.11238\tVal-quantile:35.00455\n",
      "[45]\tTrain-quantile:19.70403\tVal-quantile:34.74006\n",
      "[46]\tTrain-quantile:19.31928\tVal-quantile:34.49891\n",
      "[47]\tTrain-quantile:18.96041\tVal-quantile:34.26957\n",
      "[48]\tTrain-quantile:18.62635\tVal-quantile:34.05628\n",
      "[49]\tTrain-quantile:18.30946\tVal-quantile:33.85664\n",
      "[50]\tTrain-quantile:18.00738\tVal-quantile:33.66711\n",
      "[51]\tTrain-quantile:17.72726\tVal-quantile:33.49360\n",
      "[52]\tTrain-quantile:17.46489\tVal-quantile:33.33814\n",
      "[53]\tTrain-quantile:17.21942\tVal-quantile:33.17625\n",
      "[54]\tTrain-quantile:16.99411\tVal-quantile:33.03080\n",
      "[55]\tTrain-quantile:16.78058\tVal-quantile:32.89818\n",
      "[56]\tTrain-quantile:16.58199\tVal-quantile:32.77930\n",
      "[57]\tTrain-quantile:16.40031\tVal-quantile:32.65233\n",
      "[58]\tTrain-quantile:16.23400\tVal-quantile:32.55371\n",
      "[59]\tTrain-quantile:16.07498\tVal-quantile:32.45253\n",
      "[60]\tTrain-quantile:15.92355\tVal-quantile:32.35442\n",
      "[61]\tTrain-quantile:15.77377\tVal-quantile:32.26573\n",
      "[62]\tTrain-quantile:15.64019\tVal-quantile:32.18844\n",
      "[63]\tTrain-quantile:15.51705\tVal-quantile:32.10573\n",
      "[64]\tTrain-quantile:15.40487\tVal-quantile:32.02457\n",
      "[65]\tTrain-quantile:15.29750\tVal-quantile:31.95236\n",
      "[66]\tTrain-quantile:15.19698\tVal-quantile:31.87881\n",
      "[67]\tTrain-quantile:15.10038\tVal-quantile:31.81562\n",
      "[68]\tTrain-quantile:15.01407\tVal-quantile:31.74845\n",
      "[69]\tTrain-quantile:14.92574\tVal-quantile:31.68685\n",
      "[70]\tTrain-quantile:14.84173\tVal-quantile:31.63354\n",
      "[71]\tTrain-quantile:14.76279\tVal-quantile:31.59465\n",
      "[72]\tTrain-quantile:14.69352\tVal-quantile:31.55393\n",
      "[73]\tTrain-quantile:14.62286\tVal-quantile:31.50589\n",
      "[74]\tTrain-quantile:14.55425\tVal-quantile:31.46272\n",
      "[75]\tTrain-quantile:14.48829\tVal-quantile:31.42073\n",
      "[76]\tTrain-quantile:14.42647\tVal-quantile:31.38328\n",
      "[77]\tTrain-quantile:14.37391\tVal-quantile:31.34428\n",
      "[78]\tTrain-quantile:14.31632\tVal-quantile:31.31503\n",
      "[79]\tTrain-quantile:14.26775\tVal-quantile:31.28696\n",
      "[80]\tTrain-quantile:14.22333\tVal-quantile:31.25463\n",
      "[81]\tTrain-quantile:14.17255\tVal-quantile:31.22027\n",
      "[82]\tTrain-quantile:14.13241\tVal-quantile:31.18867\n",
      "[83]\tTrain-quantile:14.08456\tVal-quantile:31.16309\n",
      "[84]\tTrain-quantile:14.04065\tVal-quantile:31.14302\n",
      "[85]\tTrain-quantile:14.00244\tVal-quantile:31.12764\n",
      "[86]\tTrain-quantile:13.96332\tVal-quantile:31.10320\n",
      "[87]\tTrain-quantile:13.92071\tVal-quantile:31.07753\n",
      "[88]\tTrain-quantile:13.88513\tVal-quantile:31.05733\n",
      "[89]\tTrain-quantile:13.84976\tVal-quantile:31.03206\n",
      "[90]\tTrain-quantile:13.82105\tVal-quantile:30.99076\n",
      "[91]\tTrain-quantile:13.78629\tVal-quantile:30.97316\n",
      "[92]\tTrain-quantile:13.75141\tVal-quantile:30.96343\n",
      "[93]\tTrain-quantile:13.72049\tVal-quantile:30.94916\n",
      "[94]\tTrain-quantile:13.69346\tVal-quantile:30.93649\n",
      "[95]\tTrain-quantile:13.66418\tVal-quantile:30.92310\n",
      "[96]\tTrain-quantile:13.63297\tVal-quantile:30.90862\n",
      "[97]\tTrain-quantile:13.60463\tVal-quantile:30.89794\n",
      "[98]\tTrain-quantile:13.57369\tVal-quantile:30.88396\n",
      "[99]\tTrain-quantile:13.54647\tVal-quantile:30.87710\n",
      "[100]\tTrain-quantile:13.52426\tVal-quantile:30.85710\n",
      "[101]\tTrain-quantile:13.49691\tVal-quantile:30.84952\n",
      "[102]\tTrain-quantile:13.46806\tVal-quantile:30.83851\n",
      "[103]\tTrain-quantile:13.44617\tVal-quantile:30.82541\n",
      "[104]\tTrain-quantile:13.41833\tVal-quantile:30.81776\n",
      "[105]\tTrain-quantile:13.39730\tVal-quantile:30.81016\n",
      "[106]\tTrain-quantile:13.37794\tVal-quantile:30.80791\n",
      "[107]\tTrain-quantile:13.35385\tVal-quantile:30.79293\n",
      "[108]\tTrain-quantile:13.33033\tVal-quantile:30.78046\n",
      "[109]\tTrain-quantile:13.30773\tVal-quantile:30.76574\n",
      "[110]\tTrain-quantile:13.28871\tVal-quantile:30.75405\n",
      "[111]\tTrain-quantile:13.26818\tVal-quantile:30.73999\n",
      "[112]\tTrain-quantile:13.25077\tVal-quantile:30.73401\n",
      "[113]\tTrain-quantile:13.23072\tVal-quantile:30.72664\n",
      "[114]\tTrain-quantile:13.21345\tVal-quantile:30.72251\n",
      "[115]\tTrain-quantile:13.19530\tVal-quantile:30.71802\n",
      "[116]\tTrain-quantile:13.18032\tVal-quantile:30.71035\n",
      "[117]\tTrain-quantile:13.16115\tVal-quantile:30.70146\n",
      "[118]\tTrain-quantile:13.14625\tVal-quantile:30.69762\n",
      "[119]\tTrain-quantile:13.13127\tVal-quantile:30.69608\n",
      "[120]\tTrain-quantile:13.11801\tVal-quantile:30.69247\n",
      "[121]\tTrain-quantile:13.10062\tVal-quantile:30.68916\n",
      "[122]\tTrain-quantile:13.08057\tVal-quantile:30.68548\n",
      "[123]\tTrain-quantile:13.05868\tVal-quantile:30.68711\n",
      "[124]\tTrain-quantile:13.04048\tVal-quantile:30.68031\n",
      "[125]\tTrain-quantile:13.02797\tVal-quantile:30.67455\n",
      "[126]\tTrain-quantile:13.01448\tVal-quantile:30.67051\n",
      "[127]\tTrain-quantile:12.99895\tVal-quantile:30.66618\n",
      "[128]\tTrain-quantile:12.98187\tVal-quantile:30.66245\n",
      "[129]\tTrain-quantile:12.96548\tVal-quantile:30.65966\n",
      "[130]\tTrain-quantile:12.95269\tVal-quantile:30.66002\n",
      "[131]\tTrain-quantile:12.93950\tVal-quantile:30.65530\n",
      "[132]\tTrain-quantile:12.92487\tVal-quantile:30.65193\n",
      "[133]\tTrain-quantile:12.91394\tVal-quantile:30.64932\n",
      "[134]\tTrain-quantile:12.90262\tVal-quantile:30.64690\n",
      "[135]\tTrain-quantile:12.88789\tVal-quantile:30.64394\n",
      "[136]\tTrain-quantile:12.87449\tVal-quantile:30.64259\n",
      "[137]\tTrain-quantile:12.85888\tVal-quantile:30.64159\n",
      "[138]\tTrain-quantile:12.84615\tVal-quantile:30.63948\n",
      "[139]\tTrain-quantile:12.83627\tVal-quantile:30.63545\n",
      "[140]\tTrain-quantile:12.82487\tVal-quantile:30.61835\n",
      "[141]\tTrain-quantile:12.81507\tVal-quantile:30.61496\n",
      "[142]\tTrain-quantile:12.80420\tVal-quantile:30.61021\n",
      "[143]\tTrain-quantile:12.79593\tVal-quantile:30.60504\n",
      "[144]\tTrain-quantile:12.78770\tVal-quantile:30.60951\n",
      "[145]\tTrain-quantile:12.77903\tVal-quantile:30.61300\n",
      "[146]\tTrain-quantile:12.77015\tVal-quantile:30.61391\n",
      "[147]\tTrain-quantile:12.75942\tVal-quantile:30.61997\n",
      "[148]\tTrain-quantile:12.75065\tVal-quantile:30.62103\n",
      "[149]\tTrain-quantile:12.74067\tVal-quantile:30.62454\n",
      "[150]\tTrain-quantile:12.73305\tVal-quantile:30.62965\n",
      "[151]\tTrain-quantile:12.72520\tVal-quantile:30.63094\n",
      "[152]\tTrain-quantile:12.71551\tVal-quantile:30.63210\n",
      "Saved new XGBoost model to xgboost_model_wind\\xgboost_model.json\n",
      "XGBoost Pinball Score: 61.58391547212908\n"
     ]
    }
   ],
   "source": [
    "import model_utils\n",
    "\n",
    "feature_engineerer_wind = FeatureEngineerer(merged_hornsea.drop([\"sin_dayofweek\", \"cos_dayofweek\"], axis = 1), label = 'Wind_MWh_credit')\n",
    "\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "model_save_dir_xgboost = \"xgboost_model_wind\"\n",
    "\n",
    "hyperparams = {\"objective\": \"reg:quantileerror\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"quantile_alpha\": quantiles,\n",
    "            \"learning_rate\": 0.005,\n",
    "            \"max_depth\": 8}\n",
    "\n",
    "xgboost_model_wind = model_utils.XGBoostModel(feature_engineerer_wind, quantiles=quantiles, model_save_dir=model_save_dir_xgboost, load_pretrained=False, \n",
    "                                              #hyperparams = hyperparams\n",
    "                                              )\n",
    "xgboost_model_wind.train_and_predict()  # This will skip training if the model is already loaded\n",
    "print(f\"XGBoost Pinball Score: {xgboost_model_wind.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Solar Energy Forecast__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__baseline modell__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Quantile Regressor model for quantile 0.1 to qr_model_solar\\qr_model_quantile_0.1.pkl\n",
      "Saved Quantile Regressor model for quantile 0.2 to qr_model_solar\\qr_model_quantile_0.2.pkl\n",
      "Saved Quantile Regressor model for quantile 0.30000000000000004 to qr_model_solar\\qr_model_quantile_0.30000000000000004.pkl\n",
      "Saved Quantile Regressor model for quantile 0.4 to qr_model_solar\\qr_model_quantile_0.4.pkl\n",
      "Saved Quantile Regressor model for quantile 0.5 to qr_model_solar\\qr_model_quantile_0.5.pkl\n",
      "Saved Quantile Regressor model for quantile 0.6 to qr_model_solar\\qr_model_quantile_0.6.pkl\n",
      "Saved Quantile Regressor model for quantile 0.7000000000000001 to qr_model_solar\\qr_model_quantile_0.7000000000000001.pkl\n",
      "Saved Quantile Regressor model for quantile 0.8 to qr_model_solar\\qr_model_quantile_0.8.pkl\n",
      "Saved Quantile Regressor model for quantile 0.9 to qr_model_solar\\qr_model_quantile_0.9.pkl\n",
      "Quantile Regressor Pinball Score: 13.779483166533769\n"
     ]
    }
   ],
   "source": [
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"qr_model_solar\"\n",
    "\n",
    "qr_model_solar = model_utils.QuantileRegressorModel(feature_engineerer_solar_baseline, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "qr_model_solar.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {qr_model_solar.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xgboost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-quantile:44.12999\tVal-quantile:92.45223\n",
      "[1]\tTrain-quantile:42.25440\tVal-quantile:88.23172\n",
      "[2]\tTrain-quantile:40.50419\tVal-quantile:84.27149\n",
      "[3]\tTrain-quantile:38.84159\tVal-quantile:80.41121\n",
      "[4]\tTrain-quantile:37.26078\tVal-quantile:76.75385\n",
      "[5]\tTrain-quantile:35.75178\tVal-quantile:73.24482\n",
      "[6]\tTrain-quantile:34.30906\tVal-quantile:69.88570\n",
      "[7]\tTrain-quantile:32.93070\tVal-quantile:66.71439\n",
      "[8]\tTrain-quantile:31.62027\tVal-quantile:63.69509\n",
      "[9]\tTrain-quantile:30.35903\tVal-quantile:60.82798\n",
      "[10]\tTrain-quantile:29.16290\tVal-quantile:58.17260\n",
      "[11]\tTrain-quantile:28.01222\tVal-quantile:55.60625\n",
      "[12]\tTrain-quantile:26.92059\tVal-quantile:53.15848\n",
      "[13]\tTrain-quantile:25.90057\tVal-quantile:50.80891\n",
      "[14]\tTrain-quantile:24.92071\tVal-quantile:48.59624\n",
      "[15]\tTrain-quantile:23.98265\tVal-quantile:46.52111\n",
      "[16]\tTrain-quantile:23.09908\tVal-quantile:44.51724\n",
      "[17]\tTrain-quantile:22.24975\tVal-quantile:42.63751\n",
      "[18]\tTrain-quantile:21.43395\tVal-quantile:40.85613\n",
      "[19]\tTrain-quantile:20.65773\tVal-quantile:39.14182\n",
      "[20]\tTrain-quantile:19.91466\tVal-quantile:37.56037\n",
      "[21]\tTrain-quantile:19.21185\tVal-quantile:36.05928\n",
      "[22]\tTrain-quantile:18.54044\tVal-quantile:34.66540\n",
      "[23]\tTrain-quantile:17.90280\tVal-quantile:33.35458\n",
      "[24]\tTrain-quantile:17.29454\tVal-quantile:32.11310\n",
      "[25]\tTrain-quantile:16.71516\tVal-quantile:30.99450\n",
      "[26]\tTrain-quantile:16.16051\tVal-quantile:29.91241\n",
      "[27]\tTrain-quantile:15.63358\tVal-quantile:28.86422\n",
      "[28]\tTrain-quantile:15.12567\tVal-quantile:27.89221\n",
      "[29]\tTrain-quantile:14.63994\tVal-quantile:26.98894\n",
      "[30]\tTrain-quantile:14.18213\tVal-quantile:26.12916\n",
      "[31]\tTrain-quantile:13.74218\tVal-quantile:25.32689\n",
      "[32]\tTrain-quantile:13.32245\tVal-quantile:24.59017\n",
      "[33]\tTrain-quantile:12.92492\tVal-quantile:23.88891\n",
      "[34]\tTrain-quantile:12.53758\tVal-quantile:23.23372\n",
      "[35]\tTrain-quantile:12.17001\tVal-quantile:22.63008\n",
      "[36]\tTrain-quantile:11.82168\tVal-quantile:22.06110\n",
      "[37]\tTrain-quantile:11.48867\tVal-quantile:21.52378\n",
      "[38]\tTrain-quantile:11.16958\tVal-quantile:21.02354\n",
      "[39]\tTrain-quantile:10.86247\tVal-quantile:20.54309\n",
      "[40]\tTrain-quantile:10.56960\tVal-quantile:20.09154\n",
      "[41]\tTrain-quantile:10.29152\tVal-quantile:19.68438\n",
      "[42]\tTrain-quantile:10.02346\tVal-quantile:19.28842\n",
      "[43]\tTrain-quantile:9.76760\tVal-quantile:18.92094\n",
      "[44]\tTrain-quantile:9.52146\tVal-quantile:18.57198\n",
      "[45]\tTrain-quantile:9.28728\tVal-quantile:18.24388\n",
      "[46]\tTrain-quantile:9.06129\tVal-quantile:17.94320\n",
      "[47]\tTrain-quantile:8.84453\tVal-quantile:17.66110\n",
      "[48]\tTrain-quantile:8.63763\tVal-quantile:17.39037\n",
      "[49]\tTrain-quantile:8.43848\tVal-quantile:17.12573\n",
      "[50]\tTrain-quantile:8.24850\tVal-quantile:16.86949\n",
      "[51]\tTrain-quantile:8.06957\tVal-quantile:16.64367\n",
      "[52]\tTrain-quantile:7.89603\tVal-quantile:16.43557\n",
      "[53]\tTrain-quantile:7.72885\tVal-quantile:16.23184\n",
      "[54]\tTrain-quantile:7.57046\tVal-quantile:16.03783\n",
      "[55]\tTrain-quantile:7.41907\tVal-quantile:15.86178\n",
      "[56]\tTrain-quantile:7.27303\tVal-quantile:15.68770\n",
      "[57]\tTrain-quantile:7.13771\tVal-quantile:15.52184\n",
      "[58]\tTrain-quantile:7.00722\tVal-quantile:15.37116\n",
      "[59]\tTrain-quantile:6.87815\tVal-quantile:15.22611\n",
      "[60]\tTrain-quantile:6.75668\tVal-quantile:15.09017\n",
      "[61]\tTrain-quantile:6.64077\tVal-quantile:14.96280\n",
      "[62]\tTrain-quantile:6.53009\tVal-quantile:14.84812\n",
      "[63]\tTrain-quantile:6.42394\tVal-quantile:14.74258\n",
      "[64]\tTrain-quantile:6.32267\tVal-quantile:14.62913\n",
      "[65]\tTrain-quantile:6.22417\tVal-quantile:14.52587\n",
      "[66]\tTrain-quantile:6.12904\tVal-quantile:14.42897\n",
      "[67]\tTrain-quantile:6.03970\tVal-quantile:14.34057\n",
      "[68]\tTrain-quantile:5.95277\tVal-quantile:14.25120\n",
      "[69]\tTrain-quantile:5.86981\tVal-quantile:14.16907\n",
      "[70]\tTrain-quantile:5.78991\tVal-quantile:14.09497\n",
      "[71]\tTrain-quantile:5.71227\tVal-quantile:14.02544\n",
      "[72]\tTrain-quantile:5.63770\tVal-quantile:13.96207\n",
      "[73]\tTrain-quantile:5.56830\tVal-quantile:13.89327\n",
      "[74]\tTrain-quantile:5.49903\tVal-quantile:13.83301\n",
      "[75]\tTrain-quantile:5.43346\tVal-quantile:13.77962\n",
      "[76]\tTrain-quantile:5.37079\tVal-quantile:13.73045\n",
      "[77]\tTrain-quantile:5.31278\tVal-quantile:13.67908\n",
      "[78]\tTrain-quantile:5.25392\tVal-quantile:13.63285\n",
      "[79]\tTrain-quantile:5.19549\tVal-quantile:13.58622\n",
      "[80]\tTrain-quantile:5.13924\tVal-quantile:13.54806\n",
      "[81]\tTrain-quantile:5.08837\tVal-quantile:13.50577\n",
      "[82]\tTrain-quantile:5.03947\tVal-quantile:13.46742\n",
      "[83]\tTrain-quantile:4.99203\tVal-quantile:13.42552\n",
      "[84]\tTrain-quantile:4.94590\tVal-quantile:13.38592\n",
      "[85]\tTrain-quantile:4.90161\tVal-quantile:13.35330\n",
      "[86]\tTrain-quantile:4.85924\tVal-quantile:13.31770\n",
      "[87]\tTrain-quantile:4.81901\tVal-quantile:13.28603\n",
      "[88]\tTrain-quantile:4.77916\tVal-quantile:13.25479\n",
      "[89]\tTrain-quantile:4.74213\tVal-quantile:13.22518\n",
      "[90]\tTrain-quantile:4.70573\tVal-quantile:13.20168\n",
      "[91]\tTrain-quantile:4.66971\tVal-quantile:13.17553\n",
      "[92]\tTrain-quantile:4.63593\tVal-quantile:13.15050\n",
      "[93]\tTrain-quantile:4.60318\tVal-quantile:13.12337\n",
      "[94]\tTrain-quantile:4.57249\tVal-quantile:13.10298\n",
      "[95]\tTrain-quantile:4.54082\tVal-quantile:13.08272\n",
      "[96]\tTrain-quantile:4.51126\tVal-quantile:13.06041\n",
      "[97]\tTrain-quantile:4.48017\tVal-quantile:13.04104\n",
      "[98]\tTrain-quantile:4.45122\tVal-quantile:13.01927\n",
      "[99]\tTrain-quantile:4.42377\tVal-quantile:12.99961\n",
      "[100]\tTrain-quantile:4.39814\tVal-quantile:12.98059\n",
      "[101]\tTrain-quantile:4.37323\tVal-quantile:12.96310\n",
      "[102]\tTrain-quantile:4.35000\tVal-quantile:12.94971\n",
      "[103]\tTrain-quantile:4.32817\tVal-quantile:12.93318\n",
      "[104]\tTrain-quantile:4.30596\tVal-quantile:12.92056\n",
      "[105]\tTrain-quantile:4.28436\tVal-quantile:12.90624\n",
      "[106]\tTrain-quantile:4.26212\tVal-quantile:12.89270\n",
      "[107]\tTrain-quantile:4.24340\tVal-quantile:12.87973\n",
      "[108]\tTrain-quantile:4.22347\tVal-quantile:12.86392\n",
      "[109]\tTrain-quantile:4.20674\tVal-quantile:12.85160\n",
      "[110]\tTrain-quantile:4.19040\tVal-quantile:12.83975\n",
      "[111]\tTrain-quantile:4.17286\tVal-quantile:12.83227\n",
      "[112]\tTrain-quantile:4.15756\tVal-quantile:12.82421\n",
      "[113]\tTrain-quantile:4.14227\tVal-quantile:12.81390\n",
      "[114]\tTrain-quantile:4.12739\tVal-quantile:12.80592\n",
      "[115]\tTrain-quantile:4.11284\tVal-quantile:12.79350\n",
      "[116]\tTrain-quantile:4.09908\tVal-quantile:12.78658\n",
      "[117]\tTrain-quantile:4.08462\tVal-quantile:12.77489\n",
      "[118]\tTrain-quantile:4.07157\tVal-quantile:12.76921\n",
      "[119]\tTrain-quantile:4.05956\tVal-quantile:12.76061\n",
      "[120]\tTrain-quantile:4.04716\tVal-quantile:12.75401\n",
      "[121]\tTrain-quantile:4.03568\tVal-quantile:12.74868\n",
      "[122]\tTrain-quantile:4.02553\tVal-quantile:12.74250\n",
      "[123]\tTrain-quantile:4.01561\tVal-quantile:12.73786\n",
      "[124]\tTrain-quantile:4.00618\tVal-quantile:12.73338\n",
      "[125]\tTrain-quantile:3.99743\tVal-quantile:12.72480\n",
      "[126]\tTrain-quantile:3.98881\tVal-quantile:12.72051\n",
      "[127]\tTrain-quantile:3.97826\tVal-quantile:12.71623\n",
      "[128]\tTrain-quantile:3.96978\tVal-quantile:12.71344\n",
      "[129]\tTrain-quantile:3.96101\tVal-quantile:12.71037\n",
      "[130]\tTrain-quantile:3.95123\tVal-quantile:12.70729\n",
      "[131]\tTrain-quantile:3.94175\tVal-quantile:12.70687\n",
      "[132]\tTrain-quantile:3.93357\tVal-quantile:12.70344\n",
      "[133]\tTrain-quantile:3.92520\tVal-quantile:12.70106\n",
      "[134]\tTrain-quantile:3.91657\tVal-quantile:12.69746\n",
      "[135]\tTrain-quantile:3.90924\tVal-quantile:12.69486\n",
      "[136]\tTrain-quantile:3.90228\tVal-quantile:12.68921\n",
      "[137]\tTrain-quantile:3.89565\tVal-quantile:12.68696\n",
      "[138]\tTrain-quantile:3.88699\tVal-quantile:12.68592\n",
      "[139]\tTrain-quantile:3.88023\tVal-quantile:12.68334\n",
      "[140]\tTrain-quantile:3.87180\tVal-quantile:12.67916\n",
      "[141]\tTrain-quantile:3.86600\tVal-quantile:12.67713\n",
      "[142]\tTrain-quantile:3.85836\tVal-quantile:12.67308\n",
      "[143]\tTrain-quantile:3.85029\tVal-quantile:12.66953\n",
      "[144]\tTrain-quantile:3.84362\tVal-quantile:12.66927\n",
      "[145]\tTrain-quantile:3.83743\tVal-quantile:12.66704\n",
      "[146]\tTrain-quantile:3.83163\tVal-quantile:12.66744\n",
      "[147]\tTrain-quantile:3.82708\tVal-quantile:12.66545\n",
      "[148]\tTrain-quantile:3.82122\tVal-quantile:12.66604\n",
      "[149]\tTrain-quantile:3.81587\tVal-quantile:12.66838\n",
      "[150]\tTrain-quantile:3.81117\tVal-quantile:12.66679\n",
      "[151]\tTrain-quantile:3.80648\tVal-quantile:12.66701\n",
      "[152]\tTrain-quantile:3.80159\tVal-quantile:12.66349\n",
      "[153]\tTrain-quantile:3.79652\tVal-quantile:12.65990\n",
      "[154]\tTrain-quantile:3.79165\tVal-quantile:12.65740\n",
      "[155]\tTrain-quantile:3.78521\tVal-quantile:12.65610\n",
      "[156]\tTrain-quantile:3.78133\tVal-quantile:12.65590\n",
      "[157]\tTrain-quantile:3.77759\tVal-quantile:12.65567\n",
      "[158]\tTrain-quantile:3.77219\tVal-quantile:12.65593\n",
      "[159]\tTrain-quantile:3.76658\tVal-quantile:12.65387\n",
      "[160]\tTrain-quantile:3.76099\tVal-quantile:12.65209\n",
      "[161]\tTrain-quantile:3.75758\tVal-quantile:12.64972\n",
      "[162]\tTrain-quantile:3.75443\tVal-quantile:12.64873\n",
      "[163]\tTrain-quantile:3.74972\tVal-quantile:12.64630\n",
      "[164]\tTrain-quantile:3.74550\tVal-quantile:12.64684\n",
      "[165]\tTrain-quantile:3.74018\tVal-quantile:12.64755\n",
      "[166]\tTrain-quantile:3.73636\tVal-quantile:12.64713\n",
      "[167]\tTrain-quantile:3.73215\tVal-quantile:12.64884\n",
      "[168]\tTrain-quantile:3.72806\tVal-quantile:12.65073\n",
      "[169]\tTrain-quantile:3.72492\tVal-quantile:12.65237\n",
      "[170]\tTrain-quantile:3.72046\tVal-quantile:12.64969\n",
      "[171]\tTrain-quantile:3.71709\tVal-quantile:12.65042\n",
      "[172]\tTrain-quantile:3.71354\tVal-quantile:12.65062\n",
      "[173]\tTrain-quantile:3.70960\tVal-quantile:12.65063\n",
      "Saved new XGBoost model to xgboost_model_solar\\xgboost_model.json\n",
      "XGBoost Pinball Score: 12.29549740445468\n"
     ]
    }
   ],
   "source": [
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "model_save_dir_xgboost = \"xgboost_model_solar\"\n",
    "\n",
    "xgboost_model_solar = model_utils.XGBoostModel(feature_engineerer_solar, quantiles=quantiles, model_save_dir=model_save_dir_xgboost, load_pretrained=False)\n",
    "xgboost_model_solar.train_and_predict()  # This will skip training if the model is already loaded\n",
    "print(f\"XGBoost Pinball Score: {xgboost_model_solar.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Lightgbm implementation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.030927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 32.540550\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 107.268379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 234.106735\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 423.432465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.138515816261509"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "quantiles = [x for x in np.arange(0.1, 1.0, 0.1)]\n",
    "qr_solar_lightgbm = {}\n",
    "qr_solar_lightgbm[\"true\"] = feature_engineerer_solar.y_test.values\n",
    "#out_bounds_predictions = np.zeros_like(y_true_mean, dtype=np.bool_)\n",
    "for quantile in quantiles:\n",
    "    qr_lightgbm = lgb.LGBMRegressor(objective='quantile', alpha=quantile)\n",
    "    qr_lightgbm.fit(feature_engineerer_solar.X_train, feature_engineerer_solar.y_train)\n",
    "    qr_solar_lightgbm[str(quantile)] = qr_lightgbm.predict(feature_engineerer_solar.X_test)\n",
    "\n",
    "qr_solar_lightgbm_df = pd.DataFrame(qr_solar_lightgbm)\n",
    "model_utils.pinball_score(qr_solar_lightgbm_df, quantiles=quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 9.724700\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.381004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.761307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 170.074402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 260.218506\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 378.265625\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 501.830292\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 553.108765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 576.356384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "135.05236152705046"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = [x for x in np.arange(0.1, 1.0, 0.1)]\n",
    "qr_wind_lightgbm = {}\n",
    "qr_wind_lightgbm[\"true\"] = feature_engineerer_wind.y_test.values\n",
    "#out_bounds_predictions = np.zeros_like(y_true_mean, dtype=np.bool_)\n",
    "for quantile in quantiles:\n",
    "    qr_lightgbm_wind = lgb.LGBMRegressor(objective='quantile', alpha=quantile)\n",
    "    qr_lightgbm_wind.fit(feature_engineerer_wind.X_train, feature_engineerer_wind.y_train)\n",
    "    qr_wind_lightgbm[str(quantile)] = qr_lightgbm_wind.predict(feature_engineerer_wind.X_test)\n",
    "\n",
    "qr_wind_lightgbm_df = pd.DataFrame(qr_wind_lightgbm)\n",
    "model_utils.pinball_score(qr_wind_lightgbm_df, quantiles=quantiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
