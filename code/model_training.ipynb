{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import os\n",
    "import pandas as pd\n",
    "import Preprocessing_test\n",
    "\n",
    "extractor = Preprocessing_test.FileExtractor()\n",
    "\n",
    "df_dwd_hornsea = extractor.combine_files(\"data\", \"dwd_icon_eu_hornsea\")\n",
    "df_dwd_pes = extractor.combine_files(\"data\", \"dwd_icon_eu_pes10\")\n",
    "df_dwd_demand = extractor.combine_files(\"data\", \"dwd_icon_eu_demand\")\n",
    "\n",
    "ncep_gfs_hornsea = extractor.combine_files(\"data\", \"ncep_gfs_hornsea\")\n",
    "ncep_gfs_pes = extractor.combine_files(\"data\", \"ncep_gfs_pes10\")\n",
    "ncep_gfs_demand = extractor.combine_files(\"data\", \"ncep_gfs_demand\")\n",
    "\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "\n",
    "preprocesser = Preprocessing_test.Preprocessing()\n",
    "\n",
    "df_dwd_hornsea = preprocesser.preprocess_geo_data(df_dwd_hornsea)\n",
    "ncep_gfs_hornsea = preprocesser.preprocess_geo_data(ncep_gfs_hornsea)\n",
    "df_dwd_pes = preprocesser.preprocess_geo_data(df_dwd_pes)\n",
    "ncep_gfs_pes = preprocesser.preprocess_geo_data(ncep_gfs_pes)\n",
    "df_dwd_demand = preprocesser.preprocess_geo_data(df_dwd_demand)\n",
    "ncep_gfs_demand = preprocesser.preprocess_geo_data(ncep_gfs_demand)\n",
    "\n",
    "hornsea = preprocesser.merge_weather_stations_data(df_dwd_hornsea, ncep_gfs_hornsea)\n",
    "demand = preprocesser.merge_weather_stations_data(df_dwd_demand, ncep_gfs_demand)\n",
    "pes = preprocesser.merge_weather_stations_data(df_dwd_pes, ncep_gfs_pes)\n",
    "\n",
    "df_energy = extractor.combine_files(\"data\", \"Energy_data\", \".csv\")\n",
    "df_energy = preprocesser.preprocess_energy_data(df_energy)\n",
    "\n",
    "merged_hornsea = preprocesser.merge_geo_energy_outage_data(hornsea, df_energy)\n",
    "merged_pes = preprocesser.merge_geo_energy_outage_data(pes, df_energy)\n",
    "merged_demand = preprocesser.merge_geo_energy_outage_data(demand, df_energy)\n",
    "\n",
    "merged_hornsea = preprocesser.add_difference_features(merged_hornsea)\n",
    "merged_pes = preprocesser.add_difference_features(merged_pes)\n",
    "merged_demand = preprocesser.add_difference_features(merged_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Preprocessing_test\n",
    "importlib.reload(Preprocessing_test)\n",
    "\n",
    "\n",
    "feature_engineerer_wind = Preprocessing_test.FeatureEngineerer(merged_hornsea, label = 'Wind_MWh_credit')\n",
    "feature_engineerer_solar = Preprocessing_test.FeatureEngineerer(merged_pes, label = 'Solar_MWh_credit')\n",
    "\n",
    "merged_pes_simple = merged_pes[['solar_down_rad', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_solar_baseline = Preprocessing_test.FeatureEngineerer(merged_pes_simple, label = 'Solar_MWh_credit')\n",
    "\n",
    "merged_hornsea_simple = merged_hornsea[['wind_speed_100', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_wind_baseline = Preprocessing_test.FeatureEngineerer(merged_hornsea_simple, label = 'Wind_MWh_credit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Wind Energy Forecast__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__baseline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Quantile Regressor model for quantile 0.1 to qr_model_wind\\qr_model_quantile_0.1.pkl\n",
      "Saved Quantile Regressor model for quantile 0.2 to qr_model_wind\\qr_model_quantile_0.2.pkl\n",
      "Saved Quantile Regressor model for quantile 0.30000000000000004 to qr_model_wind\\qr_model_quantile_0.30000000000000004.pkl\n",
      "Saved Quantile Regressor model for quantile 0.4 to qr_model_wind\\qr_model_quantile_0.4.pkl\n",
      "Saved Quantile Regressor model for quantile 0.5 to qr_model_wind\\qr_model_quantile_0.5.pkl\n",
      "Saved Quantile Regressor model for quantile 0.6 to qr_model_wind\\qr_model_quantile_0.6.pkl\n",
      "Saved Quantile Regressor model for quantile 0.7000000000000001 to qr_model_wind\\qr_model_quantile_0.7000000000000001.pkl\n",
      "Saved Quantile Regressor model for quantile 0.8 to qr_model_wind\\qr_model_quantile_0.8.pkl\n",
      "Saved Quantile Regressor model for quantile 0.9 to qr_model_wind\\qr_model_quantile_0.9.pkl\n",
      "Quantile Regressor Pinball Score: 53.107522864798256\n"
     ]
    }
   ],
   "source": [
    "import model_utils\n",
    "import importlib\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"qr_model_wind\"\n",
    "\n",
    "qr_model = model_utils.QuantileRegressorModel(feature_engineerer_wind_baseline, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "qr_model.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {qr_model.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xgboost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-quantile:94.89053\tVal-quantile:87.66177\n",
      "[1]\tTrain-quantile:90.83282\tVal-quantile:84.57874\n",
      "[2]\tTrain-quantile:86.95141\tVal-quantile:81.63265\n",
      "[3]\tTrain-quantile:83.25112\tVal-quantile:78.92991\n",
      "[4]\tTrain-quantile:79.72649\tVal-quantile:76.32991\n",
      "[5]\tTrain-quantile:76.37012\tVal-quantile:73.85707\n",
      "[6]\tTrain-quantile:73.17085\tVal-quantile:71.50951\n",
      "[7]\tTrain-quantile:70.11194\tVal-quantile:69.26303\n",
      "[8]\tTrain-quantile:67.20466\tVal-quantile:67.13428\n",
      "[9]\tTrain-quantile:64.44692\tVal-quantile:65.10345\n",
      "[10]\tTrain-quantile:61.83717\tVal-quantile:63.18105\n",
      "[11]\tTrain-quantile:59.35552\tVal-quantile:61.35866\n",
      "[12]\tTrain-quantile:56.98392\tVal-quantile:59.67750\n",
      "[13]\tTrain-quantile:54.73463\tVal-quantile:58.04867\n",
      "[14]\tTrain-quantile:52.58143\tVal-quantile:56.50433\n",
      "[15]\tTrain-quantile:50.52961\tVal-quantile:55.07973\n",
      "[16]\tTrain-quantile:48.57692\tVal-quantile:53.67954\n",
      "[17]\tTrain-quantile:46.70945\tVal-quantile:52.35012\n",
      "[18]\tTrain-quantile:44.92951\tVal-quantile:51.12112\n",
      "[19]\tTrain-quantile:43.24020\tVal-quantile:49.94694\n",
      "[20]\tTrain-quantile:41.63434\tVal-quantile:48.87185\n",
      "[21]\tTrain-quantile:40.10049\tVal-quantile:47.85818\n",
      "[22]\tTrain-quantile:38.64372\tVal-quantile:46.88248\n",
      "[23]\tTrain-quantile:37.25737\tVal-quantile:45.97117\n",
      "[24]\tTrain-quantile:35.94063\tVal-quantile:45.08707\n",
      "[25]\tTrain-quantile:34.69571\tVal-quantile:44.25967\n",
      "[26]\tTrain-quantile:33.50253\tVal-quantile:43.50159\n",
      "[27]\tTrain-quantile:32.36896\tVal-quantile:42.76987\n",
      "[28]\tTrain-quantile:31.29352\tVal-quantile:42.08155\n",
      "[29]\tTrain-quantile:30.27034\tVal-quantile:41.41728\n",
      "[30]\tTrain-quantile:29.29899\tVal-quantile:40.80368\n",
      "[31]\tTrain-quantile:28.37071\tVal-quantile:40.22989\n",
      "[32]\tTrain-quantile:27.48419\tVal-quantile:39.66914\n",
      "[33]\tTrain-quantile:26.64601\tVal-quantile:39.15458\n",
      "[34]\tTrain-quantile:25.85846\tVal-quantile:38.65472\n",
      "[35]\tTrain-quantile:25.10775\tVal-quantile:38.18794\n",
      "[36]\tTrain-quantile:24.39565\tVal-quantile:37.72932\n",
      "[37]\tTrain-quantile:23.71954\tVal-quantile:37.31712\n",
      "[38]\tTrain-quantile:23.07724\tVal-quantile:36.92998\n",
      "[39]\tTrain-quantile:22.46457\tVal-quantile:36.55745\n",
      "[40]\tTrain-quantile:21.88713\tVal-quantile:36.22389\n",
      "[41]\tTrain-quantile:21.35512\tVal-quantile:35.89623\n",
      "[42]\tTrain-quantile:20.85258\tVal-quantile:35.60355\n",
      "[43]\tTrain-quantile:20.37411\tVal-quantile:35.33082\n",
      "[44]\tTrain-quantile:19.93882\tVal-quantile:35.04905\n",
      "[45]\tTrain-quantile:19.52942\tVal-quantile:34.79488\n",
      "[46]\tTrain-quantile:19.14331\tVal-quantile:34.56005\n",
      "[47]\tTrain-quantile:18.78205\tVal-quantile:34.34268\n",
      "[48]\tTrain-quantile:18.44749\tVal-quantile:34.14076\n",
      "[49]\tTrain-quantile:18.13111\tVal-quantile:33.94729\n",
      "[50]\tTrain-quantile:17.83639\tVal-quantile:33.75322\n",
      "[51]\tTrain-quantile:17.55738\tVal-quantile:33.58682\n",
      "[52]\tTrain-quantile:17.29424\tVal-quantile:33.41392\n",
      "[53]\tTrain-quantile:17.05114\tVal-quantile:33.25126\n",
      "[54]\tTrain-quantile:16.82014\tVal-quantile:33.10698\n",
      "[55]\tTrain-quantile:16.60104\tVal-quantile:32.97457\n",
      "[56]\tTrain-quantile:16.40491\tVal-quantile:32.83573\n",
      "[57]\tTrain-quantile:16.22169\tVal-quantile:32.72901\n",
      "[58]\tTrain-quantile:16.04920\tVal-quantile:32.62156\n",
      "[59]\tTrain-quantile:15.88139\tVal-quantile:32.50678\n",
      "[60]\tTrain-quantile:15.73009\tVal-quantile:32.39769\n",
      "[61]\tTrain-quantile:15.59467\tVal-quantile:32.30190\n",
      "[62]\tTrain-quantile:15.46431\tVal-quantile:32.21764\n",
      "[63]\tTrain-quantile:15.34129\tVal-quantile:32.13785\n",
      "[64]\tTrain-quantile:15.22669\tVal-quantile:32.07642\n",
      "[65]\tTrain-quantile:15.12224\tVal-quantile:32.00987\n",
      "[66]\tTrain-quantile:15.02104\tVal-quantile:31.94177\n",
      "[67]\tTrain-quantile:14.92649\tVal-quantile:31.87494\n",
      "[68]\tTrain-quantile:14.84158\tVal-quantile:31.81337\n",
      "[69]\tTrain-quantile:14.76363\tVal-quantile:31.75315\n",
      "[70]\tTrain-quantile:14.68530\tVal-quantile:31.69935\n",
      "[71]\tTrain-quantile:14.60553\tVal-quantile:31.64897\n",
      "[72]\tTrain-quantile:14.53609\tVal-quantile:31.58669\n",
      "[73]\tTrain-quantile:14.46907\tVal-quantile:31.53728\n",
      "[74]\tTrain-quantile:14.40525\tVal-quantile:31.49521\n",
      "[75]\tTrain-quantile:14.34615\tVal-quantile:31.44684\n",
      "[76]\tTrain-quantile:14.29393\tVal-quantile:31.40170\n",
      "[77]\tTrain-quantile:14.23985\tVal-quantile:31.36003\n",
      "[78]\tTrain-quantile:14.18050\tVal-quantile:31.32692\n",
      "[79]\tTrain-quantile:14.12748\tVal-quantile:31.29570\n",
      "[80]\tTrain-quantile:14.07278\tVal-quantile:31.26766\n",
      "[81]\tTrain-quantile:14.02917\tVal-quantile:31.23664\n",
      "[82]\tTrain-quantile:13.98306\tVal-quantile:31.20590\n",
      "[83]\tTrain-quantile:13.93860\tVal-quantile:31.18385\n",
      "[84]\tTrain-quantile:13.89689\tVal-quantile:31.15836\n",
      "[85]\tTrain-quantile:13.85845\tVal-quantile:31.13549\n",
      "[86]\tTrain-quantile:13.82104\tVal-quantile:31.11299\n",
      "[87]\tTrain-quantile:13.78282\tVal-quantile:31.08629\n",
      "[88]\tTrain-quantile:13.74580\tVal-quantile:31.07275\n",
      "[89]\tTrain-quantile:13.71079\tVal-quantile:31.05680\n",
      "[90]\tTrain-quantile:13.66829\tVal-quantile:31.03634\n",
      "[91]\tTrain-quantile:13.63681\tVal-quantile:31.01845\n",
      "[92]\tTrain-quantile:13.60501\tVal-quantile:31.00048\n",
      "[93]\tTrain-quantile:13.57547\tVal-quantile:30.98147\n",
      "[94]\tTrain-quantile:13.54163\tVal-quantile:30.96705\n",
      "[95]\tTrain-quantile:13.51469\tVal-quantile:30.95318\n",
      "[96]\tTrain-quantile:13.48195\tVal-quantile:30.94303\n",
      "[97]\tTrain-quantile:13.45807\tVal-quantile:30.92848\n",
      "[98]\tTrain-quantile:13.43137\tVal-quantile:30.91356\n",
      "[99]\tTrain-quantile:13.40497\tVal-quantile:30.90570\n",
      "[100]\tTrain-quantile:13.38327\tVal-quantile:30.89510\n",
      "[101]\tTrain-quantile:13.36372\tVal-quantile:30.88707\n",
      "[102]\tTrain-quantile:13.34577\tVal-quantile:30.87965\n",
      "[103]\tTrain-quantile:13.32600\tVal-quantile:30.87428\n",
      "[104]\tTrain-quantile:13.30501\tVal-quantile:30.86619\n",
      "[105]\tTrain-quantile:13.28409\tVal-quantile:30.85840\n",
      "[106]\tTrain-quantile:13.26457\tVal-quantile:30.84505\n",
      "[107]\tTrain-quantile:13.24546\tVal-quantile:30.83625\n",
      "[108]\tTrain-quantile:13.23036\tVal-quantile:30.82686\n",
      "[109]\tTrain-quantile:13.21115\tVal-quantile:30.81578\n",
      "[110]\tTrain-quantile:13.19147\tVal-quantile:30.80481\n",
      "[111]\tTrain-quantile:13.17044\tVal-quantile:30.79188\n",
      "[112]\tTrain-quantile:13.15011\tVal-quantile:30.78375\n",
      "[113]\tTrain-quantile:13.13440\tVal-quantile:30.78040\n",
      "[114]\tTrain-quantile:13.11640\tVal-quantile:30.76663\n",
      "[115]\tTrain-quantile:13.09960\tVal-quantile:30.76098\n",
      "[116]\tTrain-quantile:13.08028\tVal-quantile:30.76301\n",
      "[117]\tTrain-quantile:13.06383\tVal-quantile:30.75839\n",
      "[118]\tTrain-quantile:13.04666\tVal-quantile:30.75648\n",
      "[119]\tTrain-quantile:13.02526\tVal-quantile:30.75797\n",
      "[120]\tTrain-quantile:13.00640\tVal-quantile:30.75496\n",
      "[121]\tTrain-quantile:12.98675\tVal-quantile:30.74244\n",
      "[122]\tTrain-quantile:12.97048\tVal-quantile:30.74376\n",
      "[123]\tTrain-quantile:12.95247\tVal-quantile:30.74121\n",
      "[124]\tTrain-quantile:12.93933\tVal-quantile:30.73650\n",
      "[125]\tTrain-quantile:12.92033\tVal-quantile:30.73767\n",
      "[126]\tTrain-quantile:12.90558\tVal-quantile:30.72952\n",
      "[127]\tTrain-quantile:12.89209\tVal-quantile:30.72408\n",
      "[128]\tTrain-quantile:12.87592\tVal-quantile:30.71896\n",
      "[129]\tTrain-quantile:12.86208\tVal-quantile:30.71640\n",
      "[130]\tTrain-quantile:12.84768\tVal-quantile:30.71728\n",
      "[131]\tTrain-quantile:12.83586\tVal-quantile:30.71844\n",
      "[132]\tTrain-quantile:12.82257\tVal-quantile:30.71142\n",
      "[133]\tTrain-quantile:12.80812\tVal-quantile:30.70325\n",
      "[134]\tTrain-quantile:12.79687\tVal-quantile:30.69857\n",
      "[135]\tTrain-quantile:12.78545\tVal-quantile:30.69501\n",
      "[136]\tTrain-quantile:12.77439\tVal-quantile:30.69226\n",
      "[137]\tTrain-quantile:12.76388\tVal-quantile:30.69194\n",
      "[138]\tTrain-quantile:12.75359\tVal-quantile:30.69454\n",
      "[139]\tTrain-quantile:12.74390\tVal-quantile:30.69251\n",
      "[140]\tTrain-quantile:12.73339\tVal-quantile:30.70264\n",
      "[141]\tTrain-quantile:12.72254\tVal-quantile:30.70258\n",
      "[142]\tTrain-quantile:12.70828\tVal-quantile:30.69745\n",
      "[143]\tTrain-quantile:12.69812\tVal-quantile:30.69620\n",
      "[144]\tTrain-quantile:12.68522\tVal-quantile:30.68535\n",
      "[145]\tTrain-quantile:12.67199\tVal-quantile:30.69385\n",
      "[146]\tTrain-quantile:12.66276\tVal-quantile:30.69786\n",
      "[147]\tTrain-quantile:12.65139\tVal-quantile:30.69447\n",
      "[148]\tTrain-quantile:12.64351\tVal-quantile:30.68397\n",
      "[149]\tTrain-quantile:12.63242\tVal-quantile:30.67765\n",
      "[150]\tTrain-quantile:12.62527\tVal-quantile:30.67898\n",
      "[151]\tTrain-quantile:12.61486\tVal-quantile:30.67303\n",
      "[152]\tTrain-quantile:12.60828\tVal-quantile:30.67207\n",
      "[153]\tTrain-quantile:12.60114\tVal-quantile:30.67110\n",
      "[154]\tTrain-quantile:12.59526\tVal-quantile:30.67600\n",
      "[155]\tTrain-quantile:12.58917\tVal-quantile:30.67542\n",
      "[156]\tTrain-quantile:12.57823\tVal-quantile:30.67362\n",
      "[157]\tTrain-quantile:12.56843\tVal-quantile:30.66852\n",
      "[158]\tTrain-quantile:12.56168\tVal-quantile:30.66962\n",
      "[159]\tTrain-quantile:12.55610\tVal-quantile:30.67477\n",
      "[160]\tTrain-quantile:12.54772\tVal-quantile:30.66932\n",
      "[161]\tTrain-quantile:12.53941\tVal-quantile:30.67178\n",
      "[162]\tTrain-quantile:12.53125\tVal-quantile:30.67443\n",
      "[163]\tTrain-quantile:12.52387\tVal-quantile:30.67219\n",
      "[164]\tTrain-quantile:12.51620\tVal-quantile:30.67260\n",
      "[165]\tTrain-quantile:12.51031\tVal-quantile:30.67610\n",
      "[166]\tTrain-quantile:12.50325\tVal-quantile:30.67672\n",
      "Saved new XGBoost model to xgboost_model_wind\\xgboost_model.json\n",
      "XGBoost Pinball Score: 61.79941071385159\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "model_save_dir_xgboost = \"xgboost_model_wind\"\n",
    "\n",
    "xgboost_model_wind = model_utils.XGBoostModel(feature_engineerer_wind, quantiles=quantiles, model_save_dir=model_save_dir_xgboost, load_pretrained=False)\n",
    "xgboost_model_wind.train_and_predict()  # This will skip training if the model is already loaded\n",
    "print(f\"XGBoost Pinball Score: {xgboost_model_wind.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Solar Energy Forecast__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__baseline modell__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Quantile Regressor model for quantile 0.1 to qr_model_solar\\qr_model_quantile_0.1.pkl\n",
      "Saved Quantile Regressor model for quantile 0.2 to qr_model_solar\\qr_model_quantile_0.2.pkl\n",
      "Saved Quantile Regressor model for quantile 0.30000000000000004 to qr_model_solar\\qr_model_quantile_0.30000000000000004.pkl\n",
      "Saved Quantile Regressor model for quantile 0.4 to qr_model_solar\\qr_model_quantile_0.4.pkl\n",
      "Saved Quantile Regressor model for quantile 0.5 to qr_model_solar\\qr_model_quantile_0.5.pkl\n",
      "Saved Quantile Regressor model for quantile 0.6 to qr_model_solar\\qr_model_quantile_0.6.pkl\n",
      "Saved Quantile Regressor model for quantile 0.7000000000000001 to qr_model_solar\\qr_model_quantile_0.7000000000000001.pkl\n",
      "Saved Quantile Regressor model for quantile 0.8 to qr_model_solar\\qr_model_quantile_0.8.pkl\n",
      "Saved Quantile Regressor model for quantile 0.9 to qr_model_solar\\qr_model_quantile_0.9.pkl\n",
      "Quantile Regressor Pinball Score: 13.607230504775236\n"
     ]
    }
   ],
   "source": [
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"qr_model_solar\"\n",
    "\n",
    "qr_model_solar = model_utils.QuantileRegressorModel(feature_engineerer_solar_baseline, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "qr_model_solar.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {qr_model_solar.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xgboost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-quantile:44.13515\tVal-quantile:92.39949\n",
      "[1]\tTrain-quantile:42.29184\tVal-quantile:88.13729\n",
      "[2]\tTrain-quantile:40.54912\tVal-quantile:84.14312\n",
      "[3]\tTrain-quantile:38.89848\tVal-quantile:80.30528\n",
      "[4]\tTrain-quantile:37.31716\tVal-quantile:76.64144\n",
      "[5]\tTrain-quantile:35.80335\tVal-quantile:73.11867\n",
      "[6]\tTrain-quantile:34.35909\tVal-quantile:69.76359\n",
      "[7]\tTrain-quantile:32.98317\tVal-quantile:66.56863\n",
      "[8]\tTrain-quantile:31.66048\tVal-quantile:63.54328\n",
      "[9]\tTrain-quantile:30.40100\tVal-quantile:60.65396\n",
      "[10]\tTrain-quantile:29.19980\tVal-quantile:57.91469\n",
      "[11]\tTrain-quantile:28.06596\tVal-quantile:55.29548\n",
      "[12]\tTrain-quantile:26.97471\tVal-quantile:52.83934\n",
      "[13]\tTrain-quantile:25.94129\tVal-quantile:50.50737\n",
      "[14]\tTrain-quantile:24.95708\tVal-quantile:48.31265\n",
      "[15]\tTrain-quantile:24.01307\tVal-quantile:46.22179\n",
      "[16]\tTrain-quantile:23.12180\tVal-quantile:44.20001\n",
      "[17]\tTrain-quantile:22.27242\tVal-quantile:42.36014\n",
      "[18]\tTrain-quantile:21.46098\tVal-quantile:40.56213\n",
      "[19]\tTrain-quantile:20.68992\tVal-quantile:38.88628\n",
      "[20]\tTrain-quantile:19.95083\tVal-quantile:37.28595\n",
      "[21]\tTrain-quantile:19.24138\tVal-quantile:35.77380\n",
      "[22]\tTrain-quantile:18.56561\tVal-quantile:34.34646\n",
      "[23]\tTrain-quantile:17.92366\tVal-quantile:33.01074\n",
      "[24]\tTrain-quantile:17.31360\tVal-quantile:31.78844\n",
      "[25]\tTrain-quantile:16.72871\tVal-quantile:30.59207\n",
      "[26]\tTrain-quantile:16.17667\tVal-quantile:29.51721\n",
      "[27]\tTrain-quantile:15.65017\tVal-quantile:28.51213\n",
      "[28]\tTrain-quantile:15.14237\tVal-quantile:27.54636\n",
      "[29]\tTrain-quantile:14.65727\tVal-quantile:26.64383\n",
      "[30]\tTrain-quantile:14.19326\tVal-quantile:25.80998\n",
      "[31]\tTrain-quantile:13.75150\tVal-quantile:25.02436\n",
      "[32]\tTrain-quantile:13.32875\tVal-quantile:24.28190\n",
      "[33]\tTrain-quantile:12.92406\tVal-quantile:23.59371\n",
      "[34]\tTrain-quantile:12.53741\tVal-quantile:22.94894\n",
      "[35]\tTrain-quantile:12.17082\tVal-quantile:22.32014\n",
      "[36]\tTrain-quantile:11.81613\tVal-quantile:21.74514\n",
      "[37]\tTrain-quantile:11.48001\tVal-quantile:21.20963\n",
      "[38]\tTrain-quantile:11.15912\tVal-quantile:20.68819\n",
      "[39]\tTrain-quantile:10.85204\tVal-quantile:20.21831\n",
      "[40]\tTrain-quantile:10.55862\tVal-quantile:19.76243\n",
      "[41]\tTrain-quantile:10.27907\tVal-quantile:19.32727\n",
      "[42]\tTrain-quantile:10.01476\tVal-quantile:18.92850\n",
      "[43]\tTrain-quantile:9.75774\tVal-quantile:18.55531\n",
      "[44]\tTrain-quantile:9.51117\tVal-quantile:18.21272\n",
      "[45]\tTrain-quantile:9.27862\tVal-quantile:17.89045\n",
      "[46]\tTrain-quantile:9.05522\tVal-quantile:17.57653\n",
      "[47]\tTrain-quantile:8.84028\tVal-quantile:17.26569\n",
      "[48]\tTrain-quantile:8.63537\tVal-quantile:16.98044\n",
      "[49]\tTrain-quantile:8.43836\tVal-quantile:16.72666\n",
      "[50]\tTrain-quantile:8.24789\tVal-quantile:16.48248\n",
      "[51]\tTrain-quantile:8.06570\tVal-quantile:16.24670\n",
      "[52]\tTrain-quantile:7.89460\tVal-quantile:16.02485\n",
      "[53]\tTrain-quantile:7.73111\tVal-quantile:15.81900\n",
      "[54]\tTrain-quantile:7.57375\tVal-quantile:15.61244\n",
      "[55]\tTrain-quantile:7.42374\tVal-quantile:15.43403\n",
      "[56]\tTrain-quantile:7.27938\tVal-quantile:15.26090\n",
      "[57]\tTrain-quantile:7.14190\tVal-quantile:15.09715\n",
      "[58]\tTrain-quantile:7.01066\tVal-quantile:14.95017\n",
      "[59]\tTrain-quantile:6.88437\tVal-quantile:14.79641\n",
      "[60]\tTrain-quantile:6.76089\tVal-quantile:14.65822\n",
      "[61]\tTrain-quantile:6.64431\tVal-quantile:14.52588\n",
      "[62]\tTrain-quantile:6.53140\tVal-quantile:14.40401\n",
      "[63]\tTrain-quantile:6.42295\tVal-quantile:14.29858\n",
      "[64]\tTrain-quantile:6.32125\tVal-quantile:14.18436\n",
      "[65]\tTrain-quantile:6.22316\tVal-quantile:14.08176\n",
      "[66]\tTrain-quantile:6.12969\tVal-quantile:13.98832\n",
      "[67]\tTrain-quantile:6.03930\tVal-quantile:13.90587\n",
      "[68]\tTrain-quantile:5.95305\tVal-quantile:13.82164\n",
      "[69]\tTrain-quantile:5.87114\tVal-quantile:13.74485\n",
      "[70]\tTrain-quantile:5.79023\tVal-quantile:13.67603\n",
      "[71]\tTrain-quantile:5.71063\tVal-quantile:13.61091\n",
      "[72]\tTrain-quantile:5.63769\tVal-quantile:13.54579\n",
      "[73]\tTrain-quantile:5.56774\tVal-quantile:13.48078\n",
      "[74]\tTrain-quantile:5.50105\tVal-quantile:13.42626\n",
      "[75]\tTrain-quantile:5.43477\tVal-quantile:13.37044\n",
      "[76]\tTrain-quantile:5.37502\tVal-quantile:13.32339\n",
      "[77]\tTrain-quantile:5.31615\tVal-quantile:13.27154\n",
      "[78]\tTrain-quantile:5.25748\tVal-quantile:13.22295\n",
      "[79]\tTrain-quantile:5.20204\tVal-quantile:13.17712\n",
      "[80]\tTrain-quantile:5.14807\tVal-quantile:13.13212\n",
      "[81]\tTrain-quantile:5.09607\tVal-quantile:13.09119\n",
      "[82]\tTrain-quantile:5.04510\tVal-quantile:13.05293\n",
      "[83]\tTrain-quantile:4.99886\tVal-quantile:13.01462\n",
      "[84]\tTrain-quantile:4.95323\tVal-quantile:12.98112\n",
      "[85]\tTrain-quantile:4.90903\tVal-quantile:12.95014\n",
      "[86]\tTrain-quantile:4.86776\tVal-quantile:12.91498\n",
      "[87]\tTrain-quantile:4.82767\tVal-quantile:12.88646\n",
      "[88]\tTrain-quantile:4.78734\tVal-quantile:12.85794\n",
      "[89]\tTrain-quantile:4.74953\tVal-quantile:12.83191\n",
      "[90]\tTrain-quantile:4.71277\tVal-quantile:12.80700\n",
      "[91]\tTrain-quantile:4.67692\tVal-quantile:12.77991\n",
      "[92]\tTrain-quantile:4.64375\tVal-quantile:12.75619\n",
      "[93]\tTrain-quantile:4.61022\tVal-quantile:12.73315\n",
      "[94]\tTrain-quantile:4.58044\tVal-quantile:12.71344\n",
      "[95]\tTrain-quantile:4.55018\tVal-quantile:12.68963\n",
      "[96]\tTrain-quantile:4.52134\tVal-quantile:12.66894\n",
      "[97]\tTrain-quantile:4.49332\tVal-quantile:12.65000\n",
      "[98]\tTrain-quantile:4.46681\tVal-quantile:12.63445\n",
      "[99]\tTrain-quantile:4.44008\tVal-quantile:12.62099\n",
      "[100]\tTrain-quantile:4.41340\tVal-quantile:12.60759\n",
      "[101]\tTrain-quantile:4.38945\tVal-quantile:12.59186\n",
      "[102]\tTrain-quantile:4.36592\tVal-quantile:12.57570\n",
      "[103]\tTrain-quantile:4.34156\tVal-quantile:12.56567\n",
      "[104]\tTrain-quantile:4.31922\tVal-quantile:12.54828\n",
      "[105]\tTrain-quantile:4.29693\tVal-quantile:12.53529\n",
      "[106]\tTrain-quantile:4.27585\tVal-quantile:12.52368\n",
      "[107]\tTrain-quantile:4.25288\tVal-quantile:12.51268\n",
      "[108]\tTrain-quantile:4.23177\tVal-quantile:12.50391\n",
      "[109]\tTrain-quantile:4.21222\tVal-quantile:12.49213\n",
      "[110]\tTrain-quantile:4.19528\tVal-quantile:12.48531\n",
      "[111]\tTrain-quantile:4.17796\tVal-quantile:12.47648\n",
      "[112]\tTrain-quantile:4.16282\tVal-quantile:12.46841\n",
      "[113]\tTrain-quantile:4.14614\tVal-quantile:12.45889\n",
      "[114]\tTrain-quantile:4.13098\tVal-quantile:12.45071\n",
      "[115]\tTrain-quantile:4.11532\tVal-quantile:12.44331\n",
      "[116]\tTrain-quantile:4.10122\tVal-quantile:12.43483\n",
      "[117]\tTrain-quantile:4.08856\tVal-quantile:12.42677\n",
      "[118]\tTrain-quantile:4.07630\tVal-quantile:12.41311\n",
      "[119]\tTrain-quantile:4.06399\tVal-quantile:12.40824\n",
      "[120]\tTrain-quantile:4.05160\tVal-quantile:12.40285\n",
      "[121]\tTrain-quantile:4.03816\tVal-quantile:12.39973\n",
      "[122]\tTrain-quantile:4.02638\tVal-quantile:12.39147\n",
      "[123]\tTrain-quantile:4.01502\tVal-quantile:12.38754\n",
      "[124]\tTrain-quantile:4.00434\tVal-quantile:12.38198\n",
      "[125]\tTrain-quantile:3.99278\tVal-quantile:12.37889\n",
      "[126]\tTrain-quantile:3.98085\tVal-quantile:12.37758\n",
      "[127]\tTrain-quantile:3.97116\tVal-quantile:12.37539\n",
      "[128]\tTrain-quantile:3.96120\tVal-quantile:12.37193\n",
      "[129]\tTrain-quantile:3.95067\tVal-quantile:12.36867\n",
      "[130]\tTrain-quantile:3.94201\tVal-quantile:12.37096\n",
      "[131]\tTrain-quantile:3.93190\tVal-quantile:12.36755\n",
      "[132]\tTrain-quantile:3.92248\tVal-quantile:12.36459\n",
      "[133]\tTrain-quantile:3.91568\tVal-quantile:12.36337\n",
      "[134]\tTrain-quantile:3.90767\tVal-quantile:12.35892\n",
      "[135]\tTrain-quantile:3.90047\tVal-quantile:12.35916\n",
      "[136]\tTrain-quantile:3.88994\tVal-quantile:12.35614\n",
      "[137]\tTrain-quantile:3.88317\tVal-quantile:12.35831\n",
      "[138]\tTrain-quantile:3.87564\tVal-quantile:12.35702\n",
      "[139]\tTrain-quantile:3.86706\tVal-quantile:12.35702\n",
      "[140]\tTrain-quantile:3.85993\tVal-quantile:12.36003\n",
      "[141]\tTrain-quantile:3.85423\tVal-quantile:12.35990\n",
      "[142]\tTrain-quantile:3.84823\tVal-quantile:12.35969\n",
      "[143]\tTrain-quantile:3.84075\tVal-quantile:12.35922\n",
      "[144]\tTrain-quantile:3.83393\tVal-quantile:12.35926\n",
      "[145]\tTrain-quantile:3.82692\tVal-quantile:12.35969\n",
      "Saved new XGBoost model to xgboost_model_solar\\xgboost_model.json\n",
      "XGBoost Pinball Score: 12.075250299584745\n"
     ]
    }
   ],
   "source": [
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "model_save_dir_xgboost = \"xgboost_model_solar\"\n",
    "\n",
    "xgboost_model_solar = model_utils.XGBoostModel(feature_engineerer_solar, quantiles=quantiles, model_save_dir=model_save_dir_xgboost, load_pretrained=False)\n",
    "xgboost_model_solar.train_and_predict()  # This will skip training if the model is already loaded\n",
    "print(f\"XGBoost Pinball Score: {xgboost_model_solar.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Lightgbm implementation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.030927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 32.540550\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 107.268379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 234.106735\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5040\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 423.432465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.138515816261509"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "quantiles = [x for x in np.arange(0.1, 1.0, 0.1)]\n",
    "qr_solar_lightgbm = {}\n",
    "qr_solar_lightgbm[\"true\"] = feature_engineerer_solar.y_test.values\n",
    "#out_bounds_predictions = np.zeros_like(y_true_mean, dtype=np.bool_)\n",
    "for quantile in quantiles:\n",
    "    qr_lightgbm = lgb.LGBMRegressor(objective='quantile', alpha=quantile)\n",
    "    qr_lightgbm.fit(feature_engineerer_solar.X_train, feature_engineerer_solar.y_train)\n",
    "    qr_solar_lightgbm[str(quantile)] = qr_lightgbm.predict(feature_engineerer_solar.X_test)\n",
    "\n",
    "qr_solar_lightgbm_df = pd.DataFrame(qr_solar_lightgbm)\n",
    "model_utils.pinball_score(qr_solar_lightgbm_df, quantiles=quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 9.724700\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.381004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.761307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 170.074402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 260.218506\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 378.265625\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 501.830292\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 553.108765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6825\n",
      "[LightGBM] [Info] Number of data points in the train set: 48168, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 576.356384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "135.05236152705046"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = [x for x in np.arange(0.1, 1.0, 0.1)]\n",
    "qr_wind_lightgbm = {}\n",
    "qr_wind_lightgbm[\"true\"] = feature_engineerer_wind.y_test.values\n",
    "#out_bounds_predictions = np.zeros_like(y_true_mean, dtype=np.bool_)\n",
    "for quantile in quantiles:\n",
    "    qr_lightgbm_wind = lgb.LGBMRegressor(objective='quantile', alpha=quantile)\n",
    "    qr_lightgbm_wind.fit(feature_engineerer_wind.X_train, feature_engineerer_wind.y_train)\n",
    "    qr_wind_lightgbm[str(quantile)] = qr_lightgbm_wind.predict(feature_engineerer_wind.X_test)\n",
    "\n",
    "qr_wind_lightgbm_df = pd.DataFrame(qr_wind_lightgbm)\n",
    "model_utils.pinball_score(qr_wind_lightgbm_df, quantiles=quantiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HEFTcom24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
