{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils\n",
    "import pandas as pd\n",
    "\n",
    "merged_hornsea = pd.read_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "merged_pes = pd.read_parquet(\"preprocessed_pes_with_energy.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on wind and energy data at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils\n",
    "import pandas as pd\n",
    "\n",
    "merged_hornsea = pd.read_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "merged_pes = pd.read_parquet(\"preprocessed_pes_with_energy.parquet\")\n",
    "\n",
    "columns_to_add = list()\n",
    "\n",
    "for col in merged_hornsea.columns:\n",
    "    if col not in merged_pes.columns:\n",
    "        columns_to_add.append(col)\n",
    "\n",
    "merged_all = merged_pes.merge(merged_hornsea[columns_to_add], left_index = True, right_index = True)\n",
    "merged_all[\"energy\"] = merged_all[\"Solar_MWh_credit\"] + merged_all[\"Wind_MWh_credit\"]\n",
    "merged_all.drop([\"Solar_MWh_credit\", \"Wind_MWh_credit\"], axis = 1, inplace = True)\n",
    "\n",
    "from Preprocessing import *\n",
    "feature_engineerer_all = FeatureEngineerer(labels_to_remove=  [\"energy\"], columns_to_ohe = ['unavailabilityType', 'affectedUnit'], label = [\"energy\"])\n",
    "feature_engineerer_all.perform_feature_engineering(merged_all, deployment = False, labels_to_remove=  [\"energy\"])\n",
    "\n",
    "import numpy as np\n",
    "quantiles = np.arange(0.1, 1.0, 0.1).round(2)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"lgbm_mode\"\n",
    "\n",
    "lgbm_model = model_utils.LGBMRegressorModel(feature_engineerer_all, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "lgbm_model.train_and_predict()  # This will skip training for already loaded models\n",
    "\n",
    "def pinball_score(self):\n",
    "        \"\"\"pinball score implemetation\"\"\"\n",
    "\n",
    "        score = []\n",
    "        try:\n",
    "            df = pd.DataFrame(self.q_predictions)\n",
    "        except:\n",
    "            df = pd.DataFrame()\n",
    "            for k in self.q_predictions.keys():\n",
    "                df[k] = pd.DataFrame(self.q_predictions[k])\n",
    "        for qu in self.quantiles:\n",
    "            score.append(self.pinball(y=df[\"true\"], q=df[str(qu)], alpha=qu).mean())\n",
    "        return sum(score) / len(score)\n",
    "\n",
    "print(pinball_score(lgbm_model))\n",
    "# import plotly.express as px\n",
    "# df.index = feature_engineerer_all.y_test.index\n",
    "# px.line(df, y = [\"true\", \"0.5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Perform data cleaning on the weather data...\n",
      "INFO:root:Merge weather stations...\n",
      "INFO:root:Merge with outages data (REMIT)...\n",
      "c:\\Users\\danie\\Documents\\AWP2_Repo\\awp2\\Preprocessing.py:328: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  outages_df = pd.concat([outages_df, json_data_with_date_ranges])\n",
      "c:\\Users\\danie\\Documents\\AWP2_Repo\\awp2\\Preprocessing.py:328: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outages_df = pd.concat([outages_df, json_data_with_date_ranges])\n",
      "INFO:root:Merge with energy data...\n",
      "INFO:root:Preprocessing done!\n",
      "INFO:root:Perform data cleaning on the weather data...\n",
      "INFO:root:Merge weather stations...\n",
      "INFO:root:Merge with energy data...\n",
      "INFO:root:Preprocessing done!\n",
      "INFO:root:Perform data cleaning on the weather data...\n",
      "INFO:root:Merge weather stations...\n",
      "INFO:root:Merge with outages data (REMIT)...\n",
      "c:\\Users\\danie\\Documents\\AWP2_Repo\\awp2\\Preprocessing.py:328: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  outages_df = pd.concat([outages_df, json_data_with_date_ranges])\n",
      "c:\\Users\\danie\\Documents\\AWP2_Repo\\awp2\\Preprocessing.py:328: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  outages_df = pd.concat([outages_df, json_data_with_date_ranges])\n",
      "INFO:root:Merge with energy data...\n",
      "INFO:root:Preprocessing done!\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import * \n",
    "\n",
    "prep = Preprocessing()\n",
    "\n",
    "merged_hornsea = prep.perform_preprocessing_pipeline(geo_data_dict = {\"dwd_icon_eu_hornsea\":\"nc_files\", \"ncep_gfs_hornsea\":\"nc_files\"},\n",
    "                                              deployment = False, merge_with_outage_data = True, json_file_path = \"nc_files/REMIT\", energy_data_dict = {\"Energy_data\":\"csv_files\"},\n",
    "                                              non_numerical_columns = [\"unavailabilityType\", \"affectedUnit\"],\n",
    "                                              fft = False,\n",
    "                                              #columns_to_fft = [\"temp_diff\", \"solar_down_rad_diff\", \"wind_dir_sin\", \"wind_dir_cos\", \"wind_dir_100_sin\", \"wind_dir_100_cos\"]\n",
    "                                              )\n",
    "\n",
    "merged_pes = prep.perform_preprocessing_pipeline(geo_data_dict = {\"dwd_icon_eu_pes\":\"nc_files\", \"ncep_gfs_pes\":\"nc_files\"},\n",
    "          deployment = False, merge_with_outage_data = False, energy_data_dict = {\"Energy_data\":\"csv_files\"},\n",
    "                                              non_numerical_columns = [\"unavailabilityType\", \"affectedUnit\"],\n",
    "                                              fft = False, ) \n",
    "\n",
    "merged_demand = prep.perform_preprocessing_pipeline(geo_data_dict = {\"dwd_icon_eu_demand\":\"nc_files\", \"ncep_gfs_demand\":\"nc_files\"},\n",
    "          deployment = False, merge_with_outage_data = True, energy_data_dict = {\"Energy_data\":\"csv_files\"},\n",
    "                                              non_numerical_columns = [\"unavailabilityType\", \"affectedUnit\"],\n",
    "                                              fft = False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_hornsea.to_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "merged_pes.to_parquet(\"preprocessed_pes_with_energy.parquet\")\n",
    "merged_demand.to_parquet(\"preprocessed_demand_with_energy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Preprocessing\n",
    "importlib.reload(Preprocessing)\n",
    "import model_utils\n",
    "import pandas as pd\n",
    "\n",
    "merged_hornsea = pd.read_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "merged_pes = pd.read_parquet(\"preprocessed_pes_with_energy.parquet\")\n",
    "\n",
    "feature_engineerer_wind = Preprocessing.FeatureEngineerer(label = 'Wind_MWh_credit', columns_to_ohe = ['unavailabilityType', 'affectedUnit'])\n",
    "feature_engineerer_wind.perform_feature_engineering(merged_hornsea, deployment = False)\n",
    "\n",
    "feature_engineerer_solar = Preprocessing.FeatureEngineerer(label = \"Solar_MWh_credit\")\n",
    "feature_engineerer_solar.perform_feature_engineering(merged_pes, deployment = False)\n",
    "\n",
    "merged_pes_simple = merged_pes[['solar_down_rad', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_solar_baseline = Preprocessing.FeatureEngineerer(label = 'Solar_MWh_credit')\n",
    "feature_engineerer_solar_baseline.perform_feature_engineering(merged_pes_simple, deployment = False)\n",
    "\n",
    "merged_hornsea_simple = merged_hornsea[['wind_speed_100', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_wind_baseline = Preprocessing.FeatureEngineerer(label = 'Wind_MWh_credit')\n",
    "feature_engineerer_wind_baseline.perform_feature_engineering(merged_hornsea_simple, deployment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all[\"energy\"] = merged_all[\"Solar_MWh_credit\"] + merged_all[\"Wind_MWh_credit\"]\n",
    "merged_all.drop([\"Solar_MWh_credit\", \"Wind_MWh_credit\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(model_utils)\n",
    "import numpy as np\n",
    "quantiles = np.arange(0.1, 1.0, 0.1).round(2)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"lgbm_model_wind\"\n",
    "\n",
    "lgbm_model_wind = model_utils.LGBMRegressorModel(feature_engineerer_wind, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "lgbm_model_wind.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {lgbm_model_wind.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_wind.pinball_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 9.9391\tvalid's quantile: 12.6755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 9.81485\tvalid's quantile: 12.5274\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's quantile: 7.01495\tvalid's quantile: 9.66616\n",
      "[400]\ttrain's quantile: 5.36148\tvalid's quantile: 8.09251\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's quantile: 6.46146\tvalid's quantile: 8.95883\n",
      "[400]\ttrain's quantile: 5.07484\tvalid's quantile: 8.18408\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's quantile: 5.33303\tvalid's quantile: 8.14886\n",
      "[400]\ttrain's quantile: 5.15341\tvalid's quantile: 7.96792\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's quantile: 5.27433\tvalid's quantile: 8.27271\n",
      "[400]\ttrain's quantile: 4.94993\tvalid's quantile: 8.39407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 9.5396\tvalid's quantile: 12.255\n",
      "[400]\ttrain's quantile: 7.99898\tvalid's quantile: 10.5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 8.73967\tvalid's quantile: 11.0074\n",
      "[400]\ttrain's quantile: 7.18219\tvalid's quantile: 9.40928\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's quantile: 6.34639\tvalid's quantile: 8.96414\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's quantile: 6.50155\tvalid's quantile: 9.03124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 9.81039\tvalid's quantile: 12.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 9.49694\tvalid's quantile: 12.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 10.3203\tvalid's quantile: 13.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 10.2804\tvalid's quantile: 13.0943\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's quantile: 5.68971\tvalid's quantile: 8.29082\n",
      "[400]\ttrain's quantile: 5.08597\tvalid's quantile: 7.9485\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's quantile: 5.24358\tvalid's quantile: 8.10704\n",
      "[400]\ttrain's quantile: 4.52035\tvalid's quantile: 8.04751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\awp2\\Lib\\site-packages\\lightgbm\\callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's quantile: 5.52975\tvalid's quantile: 8.08038\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "import numpy as np\n",
    "quantiles = np.arange(0.1, 1.0, 0.1).round(2)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"lgbm_model_solar\"\n",
    "\n",
    "lgbm_model_solar = model_utils.LGBMRegressorModel(feature_engineerer_solar, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "lgbm_model_solar.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {lgbm_model_solar.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_solar.pinball_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(model_utils)\n",
    "import numpy as np\n",
    "quantiles = np.arange(0.1, 1.0, 0.1).round(2)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"lgbm_model_wind\"\n",
    "\n",
    "lgbm_model_wind = model_utils.LGBMRegressorModel(feature_engineerer_wind, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "lgbm_model_wind.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {lgbm_model_wind.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_wind.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_wind.q_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg2.pinball_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg2.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Preprocessing\n",
    "importlib.reload(Preprocessing)\n",
    "import model_utils\n",
    "import pandas as pd\n",
    "\n",
    "merged_hornsea = pd.read_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "merged_pes = pd.read_parquet(\"preprocessed_pes_with_energy.parquet\")\n",
    "\n",
    "feature_engineerer_wind = Preprocessing.FeatureEngineerer(label = 'Wind_MWh_credit', columns_to_ohe = ['unavailabilityType', 'affectedUnit'])\n",
    "feature_engineerer_wind.perform_feature_engineering(merged_hornsea.drop([\"rel_hum\", \"rel_hum_diff\"], axis = 1), deployment = False)\n",
    "\n",
    "feature_engineerer_solar = Preprocessing.FeatureEngineerer(label = \"Solar_MWh_credit\")\n",
    "feature_engineerer_solar.perform_feature_engineering(merged_pes, deployment = False)\n",
    "\n",
    "merged_pes_simple = merged_pes[['solar_down_rad', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_solar_baseline = Preprocessing.FeatureEngineerer(label = 'Solar_MWh_credit')\n",
    "feature_engineerer_solar_baseline.perform_feature_engineering(merged_pes_simple, deployment = False)\n",
    "\n",
    "merged_hornsea_simple = merged_hornsea[['wind_speed_100', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_wind_baseline = Preprocessing.FeatureEngineerer(label = 'Wind_MWh_credit')\n",
    "feature_engineerer_wind_baseline.perform_feature_engineering(merged_hornsea_simple, deployment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing import * \n",
    "\n",
    "prep = Preprocessing()\n",
    "\n",
    "merged_pes2 = prep.perform_preprocessing_pipeline(geo_data_dict = {\"dwd_icon_eu_pes\":\"api_files\", \"ncep_gfs_pes\":\"api_files\"},\n",
    "          deployment = True, merge_with_outage_data = False, energy_data_dict = {\"Energy_Data\":\"api_files\"},\n",
    "                                              non_numerical_columns = [\"unavailabilityType\", \"affectedUnit\"],\n",
    "                                              fft = False, )\n",
    "\n",
    "merged_hornsea2 = prep.perform_preprocessing_pipeline(geo_data_dict = {\"dwd_icon_eu_hornsea\":\"api_files\", \"ncep_gfs_hornsea\":\"api_files\"},\n",
    "          deployment = True, merge_with_outage_data = True, energy_data_dict = {\"Energy_Data\":\"api_files\"},\n",
    "                                              non_numerical_columns = [\"unavailabilityType\", \"affectedUnit\"],\n",
    "                                              fft = False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineerer_wind.perform_feature_engineering(merged_hornsea2, deployment = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineerer_solar.perform_feature_engineering(merged_pes2, deployment = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Wind Energy Forecast__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__baseline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils\n",
    "import numpy as np\n",
    "import importlib\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "quantiles = np.arange(0.1, 1.0, 0.1).round(2)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"qr_model_wind\"\n",
    "\n",
    "qr_model_wind = model_utils.QuantileRegressorModel(feature_engineerer_wind_baseline, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=True)\n",
    "qr_model_wind.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {qr_model_wind.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_model_wind.plot_quantils(feature_engineerer_wind_baseline.y_test.index, qr_model_wind.q_predictions, quantiles=np.arange(0.1, 1.0, 0.1), year=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xgboost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(model_utils)\n",
    "import numpy as np\n",
    "\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "model_save_dir_xgboost = \"xgboost_model_wind\"\n",
    "hyperparams = {\n",
    "            # Use the quantile objective function.\n",
    "            \"objective\": \"reg:quantileerror\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"quantile_alpha\": quantiles,\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"max_depth\": 8\n",
    "        }\n",
    "\n",
    "xgboost_model_wind = model_utils.XGBoostModel(feature_engineerer_wind, quantiles=quantiles, model_save_dir=model_save_dir_xgboost, load_pretrained=False, hyperparams=hyperparams, num_boost_round=45, early_stopping_rounds=10)\n",
    "xgboost_model_wind.train_and_predict()  # This will skip training if the model is already loaded\n",
    "print(f\"XGBoost Pinball Score: {xgboost_model_wind.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model_wind.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model_wind.plot_quantils(daterange=feature_engineerer_wind.y_test.index, y=xgboost_model_wind.q_predictions, quantiles=np.arange(0.1, 1.0, 0.1), year=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Solar Energy Forecast__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__baseline modell__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"qr_model_solar\"\n",
    "\n",
    "qr_model_solar = model_utils.QuantileRegressorModel(feature_engineerer_solar_baseline, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=True)\n",
    "qr_model_solar.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {qr_model_solar.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_model_solar.plot_quantils(daterange=feature_engineerer_solar_baseline.y_test.index, y=qr_model_solar.q_predictions, quantiles=np.arange(0.1, 1.0, 0.1), year=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xgboost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "model_save_dir_xgboost = \"xgboost_model_solar\"\n",
    "\n",
    "xgboost_model_solar = model_utils.XGBoostModel(feature_engineerer_solar, quantiles=quantiles, model_save_dir=model_save_dir_xgboost, load_pretrained=False)\n",
    "xgboost_model_solar.train_and_predict()  # This will skip training if the model is already loaded\n",
    "print(f\"XGBoost Pinball Score: {xgboost_model_solar.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model_solar.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model_solar.plot_quantils(daterange=feature_engineerer_solar.y_test.index, y=xgboost_model_solar.q_predictions, quantiles=np.arange(0.1, 1.0, 0.1), year=2023, month = 7, day = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Lightgbm implementation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(model_utils)\n",
    "import numpy as np\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"lgbm_model_wind\"\n",
    "\n",
    "lgbm_model_wind = model_utils.LGBMRegressorModel(feature_engineerer_wind, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "lgbm_model_wind.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {lgbm_model_wind.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_wind.plot_quantils(feature_engineerer_wind.y_test.index, lgbm_model_wind.q_predictions, quantiles, year = 2023, month=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_wind.plot_quantils(feature_engineerer_wind.y_test.index, lgbm_model_wind.q_predictions, quantiles, year = 2023, month=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_wind.q_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Specify model save directory\n",
    "model_save_dir_qr = \"lgbm_model_solar\"\n",
    "\n",
    "lgbm_model_solar = model_utils.LGBMRegressorModel(feature_engineerer_solar, quantiles, model_save_dir=model_save_dir_qr, load_pretrained=False)\n",
    "lgbm_model_solar.train_and_predict()  # This will skip training for already loaded models\n",
    "print(f\"Quantile Regressor Pinball Score: {lgbm_model_solar.pinball_score()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_engineerer_wind.features_after_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in feature_engineerer_wind.features_after_fe:\n",
    "    if g not in a:\n",
    "        print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_engineerer_wind.features_after_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['availableCapacity',\n",
    " 'cos_day',\n",
    " 'cos_dayofweek',\n",
    " 'cos_hour',\n",
    " 'cos_month',\n",
    " 'forecast_horizon',\n",
    " 'hoursSinceOutage',\n",
    " 'hoursUntilOutageEnd',\n",
    " 'outage',\n",
    " 'rel_hum',\n",
    " 'rel_hum_diff',\n",
    " 'sin_day',\n",
    " 'sin_dayofweek',\n",
    " 'sin_hour',\n",
    " 'sin_month',\n",
    " 'temp',\n",
    " 'temp_diff',\n",
    " 'temp_max_3h',\n",
    " 'temp_max_6h',\n",
    " 'temp_mean_3h',\n",
    " 'temp_mean_6h',\n",
    " 'temp_min_3h',\n",
    " 'temp_min_6h',\n",
    " 'temp_next_forecast',\n",
    " 'temp_range_3h',\n",
    " 'temp_std_3h',\n",
    " 'temp_std_6h',\n",
    " 'unavailableCapacity',\n",
    " 'wind_dir_100_cos',\n",
    " 'wind_dir_100_sin',\n",
    " 'wind_dir_cos',\n",
    " 'wind_dir_sin',\n",
    " 'wind_speed',\n",
    " 'wind_speed_100',\n",
    " 'wind_speed_100_diff',\n",
    " 'wind_speed_100_max_3h',\n",
    " 'wind_speed_100_max_6h',\n",
    " 'wind_speed_100_mean_3h',\n",
    " 'wind_speed_100_mean_6h',\n",
    " 'wind_speed_100_min_3h',\n",
    " 'wind_speed_100_min_6h',\n",
    " 'wind_speed_100_next_forecast',\n",
    " 'wind_speed_100_range_3h',\n",
    " 'wind_speed_100_std_3h',\n",
    " 'wind_speed_100_std_6h',\n",
    " 'wind_speed_altitude_diff',\n",
    " 'wind_speed_diff',\n",
    " 'wind_speed_max_3h',\n",
    " 'wind_speed_max_6h',\n",
    " 'wind_speed_mean_3h',\n",
    " 'wind_speed_mean_6h',\n",
    " 'wind_speed_min_3h',\n",
    " 'wind_speed_min_6h',\n",
    " 'wind_speed_next_forecast',\n",
    " 'wind_speed_range_3h',\n",
    " 'wind_speed_std_3h',\n",
    " 'wind_speed_std_6h',\n",
    " 'unavailabilityType_None',\n",
    " 'unavailabilityType_Planned',\n",
    " 'unavailabilityType_Unplanned',\n",
    " 'affectedUnit_HOWAO-1',\n",
    " 'affectedUnit_HOWAO-2',\n",
    " 'affectedUnit_HOWAO-3',\n",
    " 'affectedUnit_HOWBO-1',\n",
    " 'affectedUnit_HOWBO-3',\n",
    " 'affectedUnit_None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming `model` is your trained model\n",
    "with open('lgbm_model_wind.pkl', 'wb') as file:\n",
    "    pickle.dump(lgbm_model_wind, file)\n",
    "with open('lgbm_model_solar.pkl', 'wb') as file:\n",
    "    pickle.dump(lgbm_model_solar, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_solar.plot_quantils(feature_engineerer_solar.y_test.index, lgbm_model_solar.q_predictions, quantiles, year=2023, month=6, day=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "import neural_networks\n",
    "from neural_networks import *\n",
    "\n",
    "import Preprocessing\n",
    "\n",
    "import model_utils\n",
    "import pandas as pd\n",
    "\n",
    "merged_hornsea = pd.read_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "\n",
    "feature_engineerer_wind = Preprocessing.FeatureEngineerer(label = 'Wind_MWh_credit', columns_to_ohe = ['unavailabilityType', 'affectedUnit'])\n",
    "feature_engineerer_wind.perform_feature_engineering(merged_hornsea, deployment = False)\n",
    "\n",
    "class q_model2(neural_networks.q_model):\n",
    "    def __init__(self, quantiles, \n",
    "                 in_shape=50,  \n",
    "                 dropout=0.5,\n",
    "                 len_features=66):\n",
    "        super().__init__(quantiles = quantiles, in_shape = in_shape, dropout = dropout, len_features = len_features)\n",
    "\n",
    "    def build_model(self): \n",
    "        #LSTMs cannot be used inside nn.Sequential because they return tuples\n",
    "        #self.cnn1 = nn.Conv1d(self.len_features, 32, 3)\n",
    "        # self.cnn2 = nn.Conv1d(16, 32, 8)\n",
    "        # self.cnn2 = nn.Conv1d(32, 64, 8)\n",
    "        #self.bn1 = nn.BatchNorm1d(self.len_features)\n",
    "        self.lstm1 = nn.LSTM(self.len_features, 30, dropout=0.3, batch_first=True)\n",
    "        self.linear1 = nn.Linear(30, 20)\n",
    "        # self.linear2 = nn.Linear(150, 80)\n",
    "        # self.dropout2 = nn.Dropout(0.3) \n",
    "        # self.linear3 = nn.Linear(80, 40)\n",
    "        # self.dropout3 = nn.Dropout(0.3) \n",
    "        # self.linear4 = nn.Linear(50, 20)\n",
    "        self.dropout1 = nn.Dropout(0.3) \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        \n",
    "        # Final layers for quantiles\n",
    "        final_layers = [\n",
    "            nn.Linear(20, 1) for _ in range(len(self.quantiles))\n",
    "        ]\n",
    "        self.final_layers = nn.ModuleList(final_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape (batch_size, seq_len, len_features)\n",
    "        \n",
    "        # LSTM layers - extracting the output (not hidden and cell states)\n",
    "        # out = self.cnn1(x)\n",
    "        #out = self.bn1(x)\n",
    "        #out = self.bn1 = nn.BatchNorm1d(self.len_features)\n",
    "        out, _ = self.lstm1(out)\n",
    "        out = self.activation(out)\n",
    "        # # out, _ = self.lstm2(out)\n",
    "        # # out, _ = self.lstm3(out)\n",
    "\n",
    "        out = self.linear1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.activation(out)\n",
    "        # out = self.linear2(out)\n",
    "        # out = self.activation(out)\n",
    "        # out = self.dropout2(out)\n",
    "        # out = self.linear3(out)\n",
    "        # out = self.activation(out)\n",
    "        # out = self.dropout3(out)\n",
    "        # out = self.linear4(out)\n",
    "        # out = self.activation(out)\n",
    "        # out = self.dropout4(out)\n",
    "        \n",
    "        \n",
    "        # Apply final layers to get quantile outputs\n",
    "        quantile_outputs = [layer(out) for layer in self.final_layers]\n",
    "        \n",
    "        return torch.cat(quantile_outputs, dim=-1)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in [self.linear1, \n",
    "                #   self.linear2, \n",
    "                #   self.linear3, \n",
    "                  #self.linear4\n",
    "                  ]:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)  \n",
    "        for m in chain(self.final_layers):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)   \n",
    "\n",
    "q2 = q_model2\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "nn_wind = neural_networks.Trainer(feature_engineerer_wind,  q_model2,quantiles, lr = 0.01, batch_size = 48)\n",
    "nn_wind.train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wind.plot_quantils(feature_engineerer_wind.y_test.index, nn_wind.q_prediction_nn, quantiles, month = 6, year = 2023, day = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wind.plot_quantils(feature_engineerer_wind.y_test.index, nn_wind.q_prediction_nn, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Preprocessing\n",
    "importlib.reload(Preprocessing)\n",
    "\n",
    "import model_utils\n",
    "import pandas as pd\n",
    "\n",
    "merged_hornsea = pd.read_parquet(\"preprocessed_hornsea_with_energy.parquet\")\n",
    "merged_pes = pd.read_parquet(\"preprocessed_pes_with_energy.parquet\")\n",
    "\n",
    "feature_engineerer_wind = Preprocessing.FeatureEngineerer(label = 'Wind_MWh_credit', columns_to_ohe = ['unavailabilityType', 'affectedUnit'])\n",
    "feature_engineerer_wind.perform_feature_engineering(merged_hornsea, deployment = False)\n",
    "\n",
    "feature_engineerer_solar = Preprocessing.FeatureEngineerer(label = \"Solar_MWh_credit\")\n",
    "feature_engineerer_solar.perform_feature_engineering(merged_pes, deployment = False)\n",
    "\n",
    "merged_pes_simple = merged_pes[['solar_down_rad', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_solar_baseline = Preprocessing.FeatureEngineerer(label = 'Solar_MWh_credit')\n",
    "feature_engineerer_solar_baseline.perform_feature_engineering(merged_pes_simple, deployment = False)\n",
    "\n",
    "merged_hornsea_simple = merged_hornsea[['wind_speed_100', 'Solar_MWh_credit', 'Wind_MWh_credit']]\n",
    "feature_engineerer_wind_baseline = Preprocessing.FeatureEngineerer(label = 'Wind_MWh_credit')\n",
    "feature_engineerer_wind_baseline.perform_feature_engineering(merged_hornsea_simple, deployment = False)\n",
    "\n",
    "import neural_networks\n",
    "import numpy as np\n",
    "importlib.reload(neural_networks)\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "nn_wind = neural_networks.Trainer(feature_engineerer_wind, neural_networks.q_model,quantiles)\n",
    "nn_wind.train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wind.plot_quantils(feature_engineerer_wind.y_test.index, nn_wind.q_prediction_nn, quantiles, year = 2023, month = 9, day = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wind.plot_quantils(feature_engineerer_wind.y_test.index, nn_wind.q_prediction_nn, quantiles, year = 2023, month = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_nn_1 = nn_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nn_wind.model, \"LSTM_Linear_Wind.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wind.plot_quantils(feature_engineerer_wind.y_test.index, nn_wind.q_prediction_nn, quantiles, day=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_networks\n",
    "importlib.reload(neural_networks)\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "nn_solar = neural_networks.Trainer(feature_engineerer_solar, neural_networks.q_model, quantiles, in_shape=30)\n",
    "nn_solar.train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_solar.plot_quantils(feature_engineerer_solar.y_test.index, nn_solar.q_prediction_nn, quantiles, day=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
